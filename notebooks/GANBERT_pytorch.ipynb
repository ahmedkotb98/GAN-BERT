{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoeTVqrw3_ua",
        "outputId": "12bdad79-8392-4304-c0d0-df9817614f2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D87iWN_Dvlp",
        "outputId": "497099ac-2428-4fd4-e1d7-146a989cf942"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n",
            "torch.Size([2, 10]) torch.Size([2]) torch.Size([2, 5]) torch.Size([2, 7])\n"
          ]
        }
      ],
      "source": [
        "nb_samples = 100\n",
        "features = torch.randn(nb_samples, 10)\n",
        "labels = torch.empty(nb_samples, dtype=torch.long)\n",
        "adjacency = torch.randn(nb_samples, 5)\n",
        "laplacian = torch.randn(nb_samples, 7)\n",
        "\n",
        "dataset = TensorDataset(features, labels, adjacency, laplacian)\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=2\n",
        ")\n",
        "\n",
        "for batch_idx, (x, y, a, l) in enumerate(loader):\n",
        "    print(x.shape, y.shape, a.shape, l.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUpqAwtN8rTA"
      },
      "source": [
        "# GAN-BERT (in Pytorch and compatible with HuggingFace)\n",
        "\n",
        "This is a Pytorch (+ **Huggingface** transformers) implementation of the GAN-BERT model from https://github.com/crux82/ganbert. While the original GAN-BERT was an extension of BERT, this implementation can be adapted to several architectures, ranging from Roberta to Albert!\n",
        "\n",
        "**NOTE**: given that this implementation is different from the original one in Tensorflow, some results can be slighty different.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tIlJmElA3uw",
        "outputId": "326eff2e-0ca3-48fe-c948-9acf82622a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (2.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->onnxruntime) (1.15.0)\n",
            "Installing collected packages: onnxruntime\n",
            "Successfully installed onnxruntime-1.10.0\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.10.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.19.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.10.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx) (1.15.0)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.10.2\n"
          ]
        }
      ],
      "source": [
        "!pip install onnxruntime\n",
        "!pip install onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0m5KR34gmRH"
      },
      "source": [
        "Let's GO!\n",
        "\n",
        "Required Imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UIqpm34x2rms",
        "outputId": "1801a043-678b-438a-f51d-66d5746b54fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.3.2\n",
            "  Downloading transformers-4.3.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (21.3)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 31.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (4.62.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 44.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.2) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.2) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.2) (3.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.2) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.2) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.2) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.2) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.2) (7.1.2)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.3.2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import io\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "import datetime\n",
        "import torch.nn as nn\n",
        "from transformers import *\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "#!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "#!pip install sentencepiece\n",
        "\n",
        "##Set random values\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeZgRup520II",
        "outputId": "f4b05103-4c7d-4642-c2c2-df499e8808e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ],
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU3ns8Ic7I-h"
      },
      "source": [
        "### Input Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jw0HC_hU3FUy",
        "outputId": "4aee0a0e-27c8-44c7-e974-38b5c58b68d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ganbert'...\n",
            "remote: Enumerating objects: 77, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 77 (delta 33), reused 54 (delta 18), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (77/77), done.\n"
          ]
        }
      ],
      "source": [
        "#--------------------------------\n",
        "#  Transformer parameters\n",
        "#--------------------------------\n",
        "max_seq_length = 64\n",
        "batch_size = 64\n",
        "\n",
        "#--------------------------------\n",
        "#  GAN-BERT specific parameters\n",
        "#--------------------------------\n",
        "# number of hidden layers in the generator, \n",
        "# each of the size of the output space\n",
        "num_hidden_layers_g = 1; \n",
        "# number of hidden layers in the discriminator, \n",
        "# each of the size of the input space\n",
        "num_hidden_layers_d = 1; \n",
        "# size of the generator's input noisy vectors\n",
        "noise_size = 100\n",
        "# dropout to be applied to discriminator's input vectors\n",
        "out_dropout_rate = 0.2\n",
        "\n",
        "# Replicate labeled data to balance poorly represented datasets, \n",
        "# e.g., less than 1% of labeled material\n",
        "apply_balance = True\n",
        "\n",
        "#--------------------------------\n",
        "#  Optimization parameters\n",
        "#--------------------------------\n",
        "learning_rate_discriminator = 5e-5\n",
        "learning_rate_generator = 5e-5\n",
        "epsilon = 1e-8\n",
        "num_train_epochs = 8\n",
        "multi_gpu = False\n",
        "# Scheduler\n",
        "apply_scheduler = False\n",
        "warmup_proportion = 0.1\n",
        "# Print\n",
        "print_each_n_step = 10\n",
        "\n",
        "#--------------------------------\n",
        "#  Adopted Tranformer model\n",
        "#--------------------------------\n",
        "# Since this version is compatible with Huggingface transformers, you can uncomment\n",
        "# (or add) transformer models compatible with GAN\n",
        "\n",
        "model_name = \"bert-base-cased\"\n",
        "#model_name = \"bert-base-uncased\"\n",
        "#model_name = \"roberta-base\"\n",
        "#model_name = \"albert-base-v2\"\n",
        "#model_name = \"xlm-roberta-base\"\n",
        "#model_name = \"amazon/bort\"\n",
        "\n",
        "#--------------------------------\n",
        "#  Retrieve the TREC QC Dataset\n",
        "#--------------------------------\n",
        "! git clone https://github.com/crux82/ganbert\n",
        "\n",
        "#  NOTE: in this setting 50 classes are involved\n",
        "labeled_file = \"./ganbert/data/labeled.tsv\"\n",
        "unlabeled_file = \"./ganbert/data/unlabeled.tsv\"\n",
        "test_filename = \"./ganbert/data/test.tsv\"\n",
        "\n",
        "# label_list = [\"UNK_UNK\",\"ABBR_abb\", \"ABBR_exp\", \"DESC_def\", \"DESC_desc\", \n",
        "#               \"DESC_manner\", \"DESC_reason\", \"ENTY_animal\", \"ENTY_body\", \n",
        "#               \"ENTY_color\", \"ENTY_cremat\", \"ENTY_currency\", \"ENTY_dismed\", \n",
        "#               \"ENTY_event\", \"ENTY_food\", \"ENTY_instru\", \"ENTY_lang\", \n",
        "#               \"ENTY_letter\", \"ENTY_other\", \"ENTY_plant\", \"ENTY_product\", \n",
        "#               \"ENTY_religion\", \"ENTY_sport\", \"ENTY_substance\", \"ENTY_symbol\", \n",
        "#               \"ENTY_techmeth\", \"ENTY_termeq\", \"ENTY_veh\", \"ENTY_word\", \"HUM_desc\", \n",
        "#               \"HUM_gr\", \"HUM_ind\", \"HUM_title\", \"LOC_city\", \"LOC_country\", \n",
        "#               \"LOC_mount\", \"LOC_other\", \"LOC_state\", \"NUM_code\", \"NUM_count\", \n",
        "#               \"NUM_date\", \"NUM_dist\", \"NUM_money\", \"NUM_ord\", \"NUM_other\", \n",
        "#               \"NUM_perc\", \"NUM_period\", \"NUM_speed\", \"NUM_temp\", \"NUM_volsize\", \n",
        "#               \"NUM_weight\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvy8w8YOhRL2"
      },
      "source": [
        "Copy my custom train and test data from google drive to working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2xoVn3hXcT8",
        "outputId": "34979165-db13-47ee-8379-17066bdaaedc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: cannot stat 'gdrive/MyDrive/Colab Notebooks/Corona_NLP_test.csv': No such file or directory\n",
            "cp: cannot stat 'gdrive/MyDrive/Colab Notebooks/Corona_NLP_train.csv': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# os.getcwd()\n",
        "\n",
        "!cp gdrive/MyDrive/Colab\\ Notebooks/Corona_NLP_test.csv ganbert/data/\n",
        "!cp gdrive/MyDrive/Colab\\ Notebooks/Corona_NLP_train.csv ganbert/data/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d7S5LvOXmgg",
        "outputId": "897662be-2406-4672-a562-370b475de6cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Neutral' 'Positive' 'Extremely Negative' 'Negative' 'Extremely Positive']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4116, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/Corona_NLP_train.csv', encoding='latin-1')\n",
        "\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Corona_NLP_test.csv', encoding='latin-1')\n",
        "\n",
        "df_train.head()\n",
        "print(df_train.Sentiment.unique())\n",
        "df_train = df_train.sample(frac=0.1)  \n",
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7zOH9t0EiVm",
        "outputId": "1587825a-a43a-40c8-e45e-0d68e4853c93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3798, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_BxbGP2446t",
        "outputId": "e0507052-3a9b-4296-e5f1-4f1d60cf90db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "949.5"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "25/100*3798"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kAFZbdeOmTTV"
      },
      "outputs": [],
      "source": [
        "label_list = [\"UNK\", \"Neutral\", \"Positive\", \"Extremely Negative\", \"Negative\", \"Extremely Positive\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5NXrVimXnXP",
        "outputId": "95b5b569-bafd-4ec1-f55c-e2d9b9fe4390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41, 6) (4075, 6)\n"
          ]
        }
      ],
      "source": [
        "df_train_for_ganbert = df_train.sample(frac=0.01) # use 1% of the labeled data for training\n",
        "df_unlabeled = df_train.drop(df_train_for_ganbert.index)\n",
        "\n",
        "print(df_train_for_ganbert.shape, df_unlabeled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eVGLJoeJXzfa"
      },
      "outputs": [],
      "source": [
        "# Change each of the sentiment for unlabeled data to Unknown\n",
        "for i in df_unlabeled.index:\n",
        "    df_unlabeled.at[i, \"Sentiment\"] = 'UNK'\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bK7gR65BX77T"
      },
      "outputs": [],
      "source": [
        "# Defining function to format the dataset to be used in the dataloader\n",
        "def get_examples(df):\n",
        "\n",
        "    examples = []\n",
        "\n",
        "    # iterate through each row\n",
        "    for index, row in df.iterrows():\n",
        "        examples.append((row['OriginalTweet'], row['Sentiment']))\n",
        "\n",
        "    return examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WBMmHiDg98fG"
      },
      "outputs": [],
      "source": [
        "labeled_examples = get_examples(df_train_for_ganbert)\n",
        "unlabeled_examples = get_examples(df_unlabeled)\n",
        "test_examples = get_examples(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6Q5jzVioTHb"
      },
      "source": [
        "Load the Tranformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144,
          "referenced_widgets": [
            "db3276f74dec405c98d9af0131dfb8d5",
            "e9eb71d99c6643ebad3c58cbec114e87",
            "1c1b7b310796418f9e218a9ad05f9eb6",
            "309f1423c3b8496681b5c9a7a7a1adf1",
            "2ba14342d4b64dad9e2308e02cb02d4c",
            "a4ab832eb9fa45aa8ddf7a477cd29ec9",
            "af87a25ae48849eab0a17c7262529512",
            "6ad9a04a5c8a4c65bf8d9d1b45cf8055",
            "0766a1edec3d435ca50a4996f49ca495",
            "146ef28931ce457187c8160f2e07f260",
            "f773ce16b5d44bd1b8ae6e1b85734424",
            "b8570e7609ee428dbde87e174695df9a",
            "e5ae13832aa942d1987d3ed5940d2a62",
            "d34538c4da484f4b84e6e50755a68a30",
            "67b6da7e955a41e1bb48ecfead248ae8",
            "c5f7afa4dcc84134adc06bb4f5710c9f",
            "0d6c1c61001642f4a174b3fa16935b1f",
            "3291352c01fb402ab0795dbe3deb5851",
            "0c2df3b9257e4a20ba752a1f3eaaf659",
            "44e42607e9d94eb7a81b2bb756ed1142",
            "1d85ff9d1051480ca6c6e42de0c27fc7",
            "d8dd7bb2ca4d40da90eb1ded8f091c30",
            "c2da70e3699a414688b6d30ea26b883c",
            "47c4899b04af41b0846740a3cf7f194a",
            "b743c5c960434339801a1ecc8eac4a08",
            "7b7f4915558948e08adbc6d46b5fb012",
            "b1d60409ac5c4687aadee294b3d1d3cb",
            "608b69a23c254f00adf53e72bffb5b93",
            "ca0e0008c3594639a5b84df909f0e477",
            "316c589efcbe40708a355780612328d1",
            "cdcfe783b4e445e0a73bc3da5cbeffb0",
            "dcc413ecd5304b5aa0ad24b35e7b4eb3",
            "6c39bc37224449cab625edd332fc999e",
            "92d754c40ad049e18bd6b18e352b52f8",
            "7e176837f33b450e90b6d7c3ff72c498",
            "a71c6fb4b1f3412488a378d667270454",
            "9063a317e9524b189e28edc40ec49b9c",
            "b48443b07cc14955bbfd8bb6a0dc5acb",
            "42346f3ad2684476a33ff8204e5782e7",
            "e1d8d7f01bcf4fd5917a6e8138a2dbce",
            "f2f6a20fbd8d4772874c6dc0b023df02",
            "4a17014fdee44fc484e198cd3e0590ab",
            "c456f636b2cb46adbc836bb544dbac24",
            "967cc8fa506443eba1c9a8870801da3d"
          ]
        },
        "id": "gxghkkZq3Gbn",
        "outputId": "e956adb9-7cd1-4254-ae87-9570938ee6cb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db3276f74dec405c98d9af0131dfb8d5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8570e7609ee428dbde87e174695df9a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2da70e3699a414688b6d30ea26b883c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92d754c40ad049e18bd6b18e352b52f8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "transformer = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5D3H7N90nR6Z"
      },
      "outputs": [],
      "source": [
        "# torch.save(transformer, 'transformer')\n",
        "# transformer = torch.load('transformer')\n",
        "# transformer.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd_ixn5qn_zV"
      },
      "source": [
        "Function required to load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "W7cP8q7K3BId"
      },
      "outputs": [],
      "source": [
        "# def get_qc_examples(input_file):\n",
        "#   \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "#   examples = []\n",
        "\n",
        "#   with open(input_file, 'r') as f:\n",
        "#       contents = f.read()\n",
        "#       file_as_list = contents.splitlines()\n",
        "#       for line in file_as_list[1:]:\n",
        "#           split = line.split(\" \")\n",
        "#           question = ' '.join(split[1:])\n",
        "\n",
        "#           text_a = question\n",
        "#           inn_split = split[0].split(\":\")\n",
        "#           label = inn_split[0] + \"_\" + inn_split[1]\n",
        "#           examples.append((text_a, label))\n",
        "#       f.close()\n",
        "\n",
        "#   return examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K43tOavNqib4"
      },
      "source": [
        "**Load** the input QC dataset (fine-grained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cXCwFyF2qhw7"
      },
      "outputs": [],
      "source": [
        "#Load the examples\n",
        "# labeled_examples = get_qc_examples(labeled_file)\n",
        "# unlabeled_examples = get_qc_examples(unlabeled_file)\n",
        "# test_examples = get_qc_examples(test_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBhaW5vBfR6B"
      },
      "source": [
        "Functions required to convert examples into Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "fmKL5AD7I4Zg"
      },
      "outputs": [],
      "source": [
        "def generate_data_loader(input_examples, label_masks, label_map, do_shuffle = False, balance_label_examples = False):\n",
        "  '''\n",
        "  Generate a Dataloader given the input examples, eventually masked if they are \n",
        "  to be considered NOT labeled.\n",
        "  '''\n",
        "  examples = []\n",
        "\n",
        "  # Count the percentage of labeled examples  \n",
        "  num_labeled_examples = 0\n",
        "  for label_mask in label_masks:\n",
        "    if label_mask: \n",
        "      num_labeled_examples += 1\n",
        "  label_mask_rate = num_labeled_examples/len(input_examples)\n",
        "\n",
        "  # if required it applies the balance\n",
        "  for index, ex in enumerate(input_examples): \n",
        "    if label_mask_rate == 1 or not balance_label_examples:\n",
        "      examples.append((ex, label_masks[index]))\n",
        "    else:\n",
        "      # IT SIMULATE A LABELED EXAMPLE\n",
        "      if label_masks[index]:\n",
        "        balance = int(1/label_mask_rate)\n",
        "        balance = int(math.log(balance,2))\n",
        "        if balance < 1:\n",
        "          balance = 1\n",
        "        for b in range(0, int(balance)):\n",
        "          examples.append((ex, label_masks[index]))\n",
        "      else:\n",
        "        examples.append((ex, label_masks[index]))\n",
        "  \n",
        "  #-----------------------------------------------\n",
        "  # Generate input examples to the Transformer\n",
        "  #-----------------------------------------------\n",
        "  input_ids = []\n",
        "  input_mask_array = []\n",
        "  label_mask_array = []\n",
        "  label_id_array = []\n",
        "\n",
        "  # Tokenization \n",
        "  for (text, label_mask) in examples:\n",
        "    encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n",
        "    input_ids.append(encoded_sent)\n",
        "    label_id_array.append(label_map[text[1]])\n",
        "    label_mask_array.append(label_mask)\n",
        "  \n",
        "  # Attention to token (to ignore padded input wordpieces)\n",
        "  for sent in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]                          \n",
        "    input_mask_array.append(att_mask)\n",
        "  # Convertion to Tensor\n",
        "  input_ids = torch.tensor(input_ids) \n",
        "  input_mask_array = torch.tensor(input_mask_array)\n",
        "  label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n",
        "  label_mask_array = torch.tensor(label_mask_array)\n",
        "\n",
        "  # Building the TensorDataset\n",
        "  dataset = TensorDataset(input_ids, input_mask_array, label_id_array, label_mask_array)\n",
        "\n",
        "  if do_shuffle:\n",
        "    sampler = RandomSampler\n",
        "  else:\n",
        "    sampler = SequentialSampler\n",
        "\n",
        "  # Building the DataLoader\n",
        "  return DataLoader(\n",
        "              dataset,  # The training samples.\n",
        "              sampler = sampler(dataset), \n",
        "              batch_size = batch_size, # Trains with this batch size.\n",
        "              drop_last=True) \n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do3O-VeefT3g"
      },
      "source": [
        "Convert the input examples into DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4c-nsMXlKX-D"
      },
      "outputs": [],
      "source": [
        "label_map = {}\n",
        "for (i, label) in enumerate(label_list):\n",
        "  label_map[label] = i\n",
        "#------------------------------\n",
        "#   Load the train dataset\n",
        "#------------------------------\n",
        "train_examples = labeled_examples\n",
        "#The labeled (train) dataset is assigned with a mask set to True\n",
        "train_label_masks = np.ones(len(labeled_examples), dtype=bool)\n",
        "#If unlabel examples are available\n",
        "if unlabeled_examples:\n",
        "  train_examples = train_examples + unlabeled_examples\n",
        "  #The unlabeled (train) dataset is assigned with a mask set to False\n",
        "  tmp_masks = np.zeros(len(unlabeled_examples), dtype=bool)\n",
        "  train_label_masks = np.concatenate([train_label_masks,tmp_masks])\n",
        "\n",
        "train_dataloader = generate_data_loader(train_examples, train_label_masks, label_map, do_shuffle = True, balance_label_examples = apply_balance)\n",
        "\n",
        "#------------------------------\n",
        "#   Load the test dataset\n",
        "#------------------------------\n",
        "#The labeled (test) dataset is assigned with a mask set to True\n",
        "test_label_masks = np.ones(len(test_examples), dtype=bool)\n",
        "\n",
        "test_dataloader = generate_data_loader(test_examples, test_label_masks, label_map, do_shuffle = False, balance_label_examples = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ihcw3vquaQm"
      },
      "source": [
        "We define the Generator and Discriminator as discussed in https://www.aclweb.org/anthology/2020.acl-main.191/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "18kY64-n3I6y"
      },
      "outputs": [],
      "source": [
        "#------------------------------\n",
        "#   The Generator as in \n",
        "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
        "#   https://github.com/crux82/ganbert\n",
        "#------------------------------\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_size=100, output_size=512, hidden_sizes=[512], dropout_rate=0.1):\n",
        "        super(Generator, self).__init__()\n",
        "        layers = []\n",
        "        hidden_sizes = [noise_size] + hidden_sizes\n",
        "        for i in range(len(hidden_sizes)-1):\n",
        "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
        "\n",
        "        layers.append(nn.Linear(hidden_sizes[-1],output_size))\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, noise):\n",
        "        output_rep = self.layers(noise)\n",
        "        return output_rep\n",
        "\n",
        "#------------------------------\n",
        "#   The Discriminator\n",
        "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
        "#   https://github.com/crux82/ganbert\n",
        "#------------------------------\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_size=512, hidden_sizes=[512], num_labels=2, dropout_rate=0.1):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.input_dropout = nn.Dropout(p=dropout_rate)\n",
        "        layers = []\n",
        "        hidden_sizes = [input_size] + hidden_sizes\n",
        "        for i in range(len(hidden_sizes)-1):\n",
        "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
        "\n",
        "        self.layers = nn.Sequential(*layers) #per il flatten\n",
        "        self.logit = nn.Linear(hidden_sizes[-1],num_labels+1) # +1 for the probability of this sample being fake/real.\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, input_rep):\n",
        "        input_rep = self.input_dropout(input_rep)\n",
        "        last_rep = self.layers(input_rep)\n",
        "        logits = self.logit(last_rep)\n",
        "        probs = self.softmax(logits)\n",
        "        return last_rep, logits, probs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uje9s2zQunFc"
      },
      "source": [
        "We instantiate the Discriminator and Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ylz5rvqE3U2S"
      },
      "outputs": [],
      "source": [
        "# The config file is required to get the dimension of the vector produced by \n",
        "# the underlying transformer\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "hidden_size = int(config.hidden_size)\n",
        "# Define the number and width of hidden layers\n",
        "hidden_levels_g = [hidden_size for i in range(0, num_hidden_layers_g)]\n",
        "hidden_levels_d = [hidden_size for i in range(0, num_hidden_layers_d)]\n",
        "\n",
        "#-------------------------------------------------\n",
        "#   Instantiate the Generator and Discriminator\n",
        "#-------------------------------------------------\n",
        "generator = Generator(noise_size=noise_size, output_size=hidden_size, hidden_sizes=hidden_levels_g, dropout_rate=out_dropout_rate)\n",
        "discriminator = Discriminator(input_size=hidden_size, hidden_sizes=hidden_levels_d, num_labels=len(label_list), dropout_rate=out_dropout_rate)\n",
        "\n",
        "# Put everything in the GPU if available\n",
        "if torch.cuda.is_available():    \n",
        "  generator.cuda()\n",
        "  discriminator.cuda()\n",
        "  transformer.cuda()\n",
        "  if multi_gpu:\n",
        "    transformer = torch.nn.DataParallel(transformer)\n",
        "\n",
        "# print(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG3qzp2-usZE"
      },
      "source": [
        "Let's go with the training procedure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NhqylHGK3Va4",
        "outputId": "1dd3d34e-1e48-4385-9509-42b18eb9bf9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 8 ========\n",
            "Training...\n",
            "  Batch    10  of     67.    Elapsed: 0:00:21.\n",
            "  Batch    20  of     67.    Elapsed: 0:00:41.\n",
            "  Batch    30  of     67.    Elapsed: 0:01:02.\n",
            "  Batch    40  of     67.    Elapsed: 0:01:22.\n",
            "  Batch    50  of     67.    Elapsed: 0:01:42.\n",
            "  Batch    60  of     67.    Elapsed: 0:02:03.\n",
            "\n",
            "  Average training loss generetor: 0.613\n",
            "  Average training loss discriminator: 2.448\n",
            "  Training epcoh took: 0:02:17\n",
            "Saving the models...............................\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.259\n",
            "  Test Loss: 1.769\n",
            "  Test took: 0:00:27\n",
            "\n",
            "======== Epoch 2 / 8 ========\n",
            "Training...\n",
            "  Batch    10  of     67.    Elapsed: 0:00:20.\n",
            "  Batch    20  of     67.    Elapsed: 0:00:41.\n",
            "  Batch    30  of     67.    Elapsed: 0:01:01.\n",
            "  Batch    40  of     67.    Elapsed: 0:01:21.\n",
            "  Batch    50  of     67.    Elapsed: 0:01:42.\n",
            "  Batch    60  of     67.    Elapsed: 0:02:02.\n",
            "\n",
            "  Average training loss generetor: 0.743\n",
            "  Average training loss discriminator: 1.262\n",
            "  Training epcoh took: 0:02:16\n",
            "Saving the models...............................\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.172\n",
            "  Test Loss: 2.553\n",
            "  Test took: 0:00:27\n",
            "\n",
            "======== Epoch 3 / 8 ========\n",
            "Training...\n",
            "  Batch    10  of     67.    Elapsed: 0:00:20.\n",
            "  Batch    20  of     67.    Elapsed: 0:00:41.\n",
            "  Batch    30  of     67.    Elapsed: 0:01:01.\n",
            "  Batch    40  of     67.    Elapsed: 0:01:21.\n",
            "  Batch    50  of     67.    Elapsed: 0:01:42.\n",
            "  Batch    60  of     67.    Elapsed: 0:02:02.\n",
            "\n",
            "  Average training loss generetor: 0.724\n",
            "  Average training loss discriminator: 0.795\n",
            "  Training epcoh took: 0:02:16\n",
            "Saving the models...............................\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.229\n",
            "  Test Loss: 3.197\n",
            "  Test took: 0:00:27\n",
            "\n",
            "======== Epoch 4 / 8 ========\n",
            "Training...\n",
            "  Batch    10  of     67.    Elapsed: 0:00:20.\n",
            "  Batch    20  of     67.    Elapsed: 0:00:41.\n",
            "  Batch    30  of     67.    Elapsed: 0:01:01.\n",
            "  Batch    40  of     67.    Elapsed: 0:01:21.\n",
            "  Batch    50  of     67.    Elapsed: 0:01:42.\n",
            "  Batch    60  of     67.    Elapsed: 0:02:02.\n",
            "\n",
            "  Average training loss generetor: 0.717\n",
            "  Average training loss discriminator: 0.749\n",
            "  Training epcoh took: 0:02:16\n",
            "Saving the models...............................\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.234\n",
            "  Test Loss: 3.540\n",
            "  Test took: 0:00:27\n",
            "\n",
            "======== Epoch 5 / 8 ========\n",
            "Training...\n",
            "  Batch    10  of     67.    Elapsed: 0:00:20.\n",
            "  Batch    20  of     67.    Elapsed: 0:00:41.\n",
            "  Batch    30  of     67.    Elapsed: 0:01:01.\n",
            "  Batch    40  of     67.    Elapsed: 0:01:21.\n",
            "  Batch    50  of     67.    Elapsed: 0:01:42.\n",
            "  Batch    60  of     67.    Elapsed: 0:02:02.\n",
            "\n",
            "  Average training loss generetor: 0.711\n",
            "  Average training loss discriminator: 0.739\n",
            "  Training epcoh took: 0:02:16\n",
            "Saving the models...............................\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.230\n",
            "  Test Loss: 3.948\n",
            "  Test took: 0:00:27\n",
            "\n",
            "======== Epoch 6 / 8 ========\n",
            "Training...\n",
            "  Batch    10  of     67.    Elapsed: 0:00:20.\n",
            "  Batch    20  of     67.    Elapsed: 0:00:41.\n",
            "  Batch    30  of     67.    Elapsed: 0:01:01.\n",
            "  Batch    40  of     67.    Elapsed: 0:01:21.\n",
            "  Batch    50  of     67.    Elapsed: 0:01:42.\n",
            "  Batch    60  of     67.    Elapsed: 0:02:02.\n",
            "\n",
            "  Average training loss generetor: 0.710\n",
            "  Average training loss discriminator: 0.731\n",
            "  Training epcoh took: 0:02:16\n",
            "Saving the models...............................\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.242\n",
            "  Test Loss: 4.204\n",
            "  Test took: 0:00:27\n",
            "\n",
            "======== Epoch 7 / 8 ========\n",
            "Training...\n",
            "  Batch    10  of     67.    Elapsed: 0:00:20.\n",
            "  Batch    20  of     67.    Elapsed: 0:00:41.\n",
            "  Batch    30  of     67.    Elapsed: 0:01:01.\n",
            "  Batch    40  of     67.    Elapsed: 0:01:22.\n",
            "  Batch    50  of     67.    Elapsed: 0:01:42.\n",
            "  Batch    60  of     67.    Elapsed: 0:02:02.\n",
            "\n",
            "  Average training loss generetor: 0.708\n",
            "  Average training loss discriminator: 0.726\n",
            "  Training epcoh took: 0:02:16\n",
            "Saving the models...............................\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.241\n",
            "  Test Loss: 4.661\n",
            "  Test took: 0:00:27\n",
            "\n",
            "======== Epoch 8 / 8 ========\n",
            "Training...\n",
            "  Batch    10  of     67.    Elapsed: 0:00:20.\n",
            "  Batch    20  of     67.    Elapsed: 0:00:41.\n",
            "  Batch    30  of     67.    Elapsed: 0:01:01.\n",
            "  Batch    40  of     67.    Elapsed: 0:01:21.\n",
            "  Batch    50  of     67.    Elapsed: 0:01:42.\n",
            "  Batch    60  of     67.    Elapsed: 0:02:02.\n",
            "\n",
            "  Average training loss generetor: 0.707\n",
            "  Average training loss discriminator: 0.721\n",
            "  Training epcoh took: 0:02:16\n",
            "Saving the models...............................\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.246\n",
            "  Test Loss: 4.728\n",
            "  Test took: 0:00:27\n"
          ]
        }
      ],
      "source": [
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "#models parameters\n",
        "transformer_vars = [i for i in transformer.parameters()]\n",
        "d_vars = transformer_vars + [v for v in discriminator.parameters()]\n",
        "g_vars = [v for v in generator.parameters()]\n",
        "\n",
        "#optimizer\n",
        "dis_optimizer = torch.optim.AdamW(d_vars, lr=learning_rate_discriminator)\n",
        "gen_optimizer = torch.optim.AdamW(g_vars, lr=learning_rate_generator) \n",
        "\n",
        "#scheduler\n",
        "if apply_scheduler:\n",
        "  num_train_examples = len(train_examples)\n",
        "  num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n",
        "  num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
        "\n",
        "  scheduler_d = get_constant_schedule_with_warmup(dis_optimizer, \n",
        "                                           num_warmup_steps = num_warmup_steps)\n",
        "  scheduler_g = get_constant_schedule_with_warmup(gen_optimizer, \n",
        "                                           num_warmup_steps = num_warmup_steps)\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, num_train_epochs):\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    # Perform one full pass over the training set.\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_train_epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    tr_g_loss = 0\n",
        "    tr_d_loss = 0\n",
        "\n",
        "    # Put the model into training mode.\n",
        "    transformer.train() \n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every print_each_n_step batches.\n",
        "        if step % print_each_n_step == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        b_label_mask = batch[3].to(device)\n",
        "        \n",
        "        # Encode real data in the Transformer\n",
        "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
        "        hidden_states = model_outputs[-1]\n",
        "        \n",
        "        # Generate fake data that should have the same distribution of the ones\n",
        "        # encoded by the transformer. \n",
        "        # First noisy input are used in input to the Generator\n",
        "        noise = torch.zeros(b_input_ids.shape[0],noise_size, device=device).uniform_(0, 1)\n",
        "        # Gnerate Fake data\n",
        "        gen_rep = generator(noise)\n",
        "\n",
        "        # Generate the output of the Discriminator for real and fake data.\n",
        "        # First, we put together the output of the tranformer and the generator\n",
        "        disciminator_input = torch.cat([hidden_states, gen_rep], dim=0)\n",
        "        # Then, we select the output of the disciminator\n",
        "        features, logits, probs = discriminator(disciminator_input)\n",
        "\n",
        "        # Finally, we separate the discriminator's output for the real and fake\n",
        "        # data\n",
        "        features_list = torch.split(features, batch_size)\n",
        "        D_real_features = features_list[0]\n",
        "        D_fake_features = features_list[1]\n",
        "        \n",
        "        logits_list = torch.split(logits, batch_size)\n",
        "        D_real_logits = logits_list[0]\n",
        "        D_fake_logits = logits_list[1]\n",
        "        \n",
        "        probs_list = torch.split(probs, batch_size)\n",
        "        D_real_probs = probs_list[0]\n",
        "        D_fake_probs = probs_list[1]\n",
        "\n",
        "        #---------------------------------\n",
        "        #  LOSS evaluation\n",
        "        #---------------------------------\n",
        "        # Generator's LOSS estimation\n",
        "        g_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:,-1] + epsilon))\n",
        "        g_feat_reg = torch.mean(torch.pow(torch.mean(D_real_features, dim=0) - torch.mean(D_fake_features, dim=0), 2))\n",
        "        g_loss = g_loss_d + g_feat_reg\n",
        "  \n",
        "        # Disciminator's LOSS estimation\n",
        "        logits = D_real_logits[:,0:-1]\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        # The discriminator provides an output for labeled and unlabeled real data\n",
        "        # so the loss evaluated for unlabeled data is ignored (masked)\n",
        "        label2one_hot = torch.nn.functional.one_hot(b_labels, len(label_list))\n",
        "        per_example_loss = -torch.sum(label2one_hot * log_probs, dim=-1)\n",
        "        per_example_loss = torch.masked_select(per_example_loss, b_label_mask.to(device))\n",
        "        labeled_example_count = per_example_loss.type(torch.float32).numel()\n",
        "\n",
        "        # It may be the case that a batch does not contain labeled examples, \n",
        "        # so the \"supervised loss\" in this case is not evaluated\n",
        "        if labeled_example_count == 0:\n",
        "          D_L_Supervised = 0\n",
        "        else:\n",
        "          D_L_Supervised = torch.div(torch.sum(per_example_loss.to(device)), labeled_example_count)\n",
        "                 \n",
        "        D_L_unsupervised1U = -1 * torch.mean(torch.log(1 - D_real_probs[:, -1] + epsilon))\n",
        "        D_L_unsupervised2U = -1 * torch.mean(torch.log(D_fake_probs[:, -1] + epsilon))\n",
        "        d_loss = D_L_Supervised + D_L_unsupervised1U + D_L_unsupervised2U\n",
        "\n",
        "        #---------------------------------\n",
        "        #  OPTIMIZATION\n",
        "        #---------------------------------\n",
        "        # Avoid gradient accumulation\n",
        "        gen_optimizer.zero_grad()\n",
        "        dis_optimizer.zero_grad()\n",
        "\n",
        "        # Calculate weigth updates\n",
        "        # retain_graph=True is required since the underlying graph will be deleted after backward\n",
        "        g_loss.backward(retain_graph=True)\n",
        "        d_loss.backward() \n",
        "        \n",
        "        # Apply modifications\n",
        "        gen_optimizer.step()\n",
        "        dis_optimizer.step()\n",
        "   \n",
        "        # A detail log of the individual losses\n",
        "        #print(\"{0:.4f}\\t{1:.4f}\\t{2:.4f}\\t{3:.4f}\\t{4:.4f}\".\n",
        "        #      format(D_L_Supervised, D_L_unsupervised1U, D_L_unsupervised2U,\n",
        "        #             g_loss_d, g_feat_reg))\n",
        "\n",
        "        # Save the losses to print them later\n",
        "        tr_g_loss += g_loss.item()\n",
        "        tr_d_loss += d_loss.item()\n",
        "\n",
        "        # Update the learning rate with the scheduler\n",
        "        if apply_scheduler:\n",
        "          scheduler_d.step()\n",
        "          scheduler_g.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss_g = tr_g_loss / len(train_dataloader)\n",
        "    avg_train_loss_d = tr_d_loss / len(train_dataloader)             \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss generetor: {0:.3f}\".format(avg_train_loss_g))\n",
        "    print(\"  Average training loss discriminator: {0:.3f}\".format(avg_train_loss_d))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    print(\"Saving the models...............................\")\n",
        "    # Saving the model\n",
        "    torch.save(transformer, 'transformer')\n",
        "    torch.save(discriminator, 'discriminator')\n",
        "\n",
        "        \n",
        "    # ========================================\n",
        "    #     TEST ON THE EVALUATION DATASET\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our test set.\n",
        "    print(\"\")\n",
        "    print(\"Running Test...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    transformer.eval() #maybe redundant\n",
        "    discriminator.eval()\n",
        "    generator.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_test_accuracy = 0\n",
        "   \n",
        "    total_test_loss = 0\n",
        "    nb_test_steps = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels_ids = []\n",
        "\n",
        "    #loss\n",
        "    nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in test_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "            model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
        "            hidden_states = model_outputs[-1]\n",
        "            _, logits, probs = discriminator(hidden_states)\n",
        "            ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
        "            filtered_logits = logits[:,0:-1]\n",
        "            # Accumulate the test loss.\n",
        "            total_test_loss += nll_loss(filtered_logits, b_labels)\n",
        "            \n",
        "        # Accumulate the predictions and the input labels\n",
        "        _, preds = torch.max(filtered_logits, 1)\n",
        "        all_preds += preds.detach().cpu()\n",
        "        all_labels_ids += b_labels.detach().cpu()\n",
        "\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    all_preds = torch.stack(all_preds).numpy()\n",
        "    all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
        "    test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
        "    print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "    avg_test_loss = avg_test_loss.item()\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    test_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n",
        "    print(\"  Test took: {:}\".format(test_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss generator': avg_train_loss_g,\n",
        "            'Training Loss discriminator': avg_train_loss_d,\n",
        "            'Valid. Loss': avg_test_loss,\n",
        "            'Valid. Accur.': test_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Test Time': test_time\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "br24HtQtmfmf"
      },
      "outputs": [],
      "source": [
        "# Loading the saved model\n",
        "transformer = torch.load('transformer')\n",
        "discriminator = torch.load('discriminator')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylQfKGjIlkFc"
      },
      "source": [
        "#This block is created to show how to load saved model and run test.\n",
        "#I have used our test data for prediction and evaluation. You are free to use any data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb-17PXHi-cA",
        "outputId": "194c0c2b-3c70-4626-c2e8-2b124a953c8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.246\n",
            "  Test Loss: 4.728\n",
            "  Test took: 0:00:28\n"
          ]
        }
      ],
      "source": [
        "print(\"\")\n",
        "print(\"Running Test...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "transformer.eval() #maybe redundant\n",
        "discriminator.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_test_accuracy = 0\n",
        "\n",
        "total_test_loss = 0\n",
        "nb_test_steps = 0\n",
        "\n",
        "all_preds = []\n",
        "all_labels_ids = []\n",
        "\n",
        "#loss\n",
        "nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_dataloader:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
        "        hidden_states = model_outputs[-1]\n",
        "        _, logits, probs = discriminator(hidden_states)\n",
        "        ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
        "        filtered_logits = logits[:,0:-1]\n",
        "        # Accumulate the test loss.\n",
        "        total_test_loss += nll_loss(filtered_logits, b_labels)\n",
        "        \n",
        "    # Accumulate the predictions and the input labels\n",
        "    _, preds = torch.max(filtered_logits, 1)\n",
        "    all_preds += preds.detach().cpu()\n",
        "    all_labels_ids += b_labels.detach().cpu()\n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "all_preds = torch.stack(all_preds).numpy()\n",
        "all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
        "test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
        "print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "avg_test_loss = avg_test_loss.item()\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "test_time = format_time(time.time() - t0)\n",
        "  \n",
        "print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n",
        "print(\"  Test took: {:}\".format(test_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjoiGrSmpE8i",
        "outputId": "1033d953-e1dc-464f-b0da-a233dfed782c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 4, 4, ..., 5, 4, 4])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# See the predictions\n",
        "all_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDm9NProRB4c",
        "outputId": "ecc1813c-cc27-42a1-c8f9-c932217d4eb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'Training Loss generator': 0.6157938904726683, 'Training Loss discriminator': 2.457873319511983, 'Valid. Loss': 1.844170093536377, 'Valid. Accur.': 0.2576800847457627, 'Training Time': '0:02:43', 'Test Time': '0:00:33'}\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:04:36 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "for stat in training_stats:\n",
        "  print(stat)\n",
        "\n",
        "print(\"\\nTraining complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdtjzI4uOnbJ"
      },
      "source": [
        "# Convert to onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "O_QqC41NOltj"
      },
      "outputs": [],
      "source": [
        "transformer = torch.load('/content/drive/MyDrive/GANBERT2/transformer', map_location = \"cpu\")\n",
        "discriminator = torch.load('/content/drive/MyDrive/GANBERT2/discriminator', map_location = \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CX4BFMK46YDd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "8cb10fc6bcea4b1bba6a297590d734f7",
            "722bc21fb2014432bef6929b376e938d",
            "39128d6d796e40eea93edd2cb2db9f80",
            "1b1a90ef109c4918838a4bf50fafa139",
            "9c9bb34d048f4c08a649e526cccb9e9f",
            "7d6025575fd644a09b33fcf0fdd169ae",
            "a5ead7eeacd64b94862fb8ece7839d19",
            "2c64becf8e2f45d2af1ee16e0df13f9a",
            "c771720452ce47399fe09343670a672d",
            "29a8851095b846439bb87e69bb7abea2",
            "107936edf3a94ba99caf0d5de9719af0",
            "2dc26f146b95493bb1510596f810ee3c",
            "adbb88f8a62342989b397c78c7c84103",
            "83cd924ab9954ebbbba49d1e3520c6d1",
            "5a495f8cb2b3480d9ceaea787531ac5f",
            "a42ade9216fe40c199ce075ba5ec0107",
            "659527d2fe9d485886c4ff3fba9f6e88",
            "e718efddb32245fc8fc2c87f69fd3d89",
            "36666c77ec1542abbb1bb4d9bc49fc1a",
            "ebd4f61db33e4f4e994fc17b6ebeccca",
            "d026410f378d4840a22885cb0beef6d8",
            "3123da93c8914842bf5bd2afb61e7c91",
            "3092fd4dc5f140f291cbd3d733786042",
            "136f7b25b2c54ae1b57127828ccfb9a7",
            "0f33b9f20dff49f3a7f9280d7a9038f9",
            "390cc8d45a2c45929249a99fca3f4a1a",
            "1f2a30bdde554528be9b698bdd4111b0",
            "70b287b926874843a28c840b6cb43536",
            "f4f3549ee9c047d186ac85ef29376740",
            "a88a9d3b1364465b9073428a648b0bcd",
            "c50d234edbbc458a889e6de861ac5c67",
            "e8fa91e8c2e245ae9decd78274e1b823",
            "87f1706a77114eae8cc08f63cbca830b"
          ]
        },
        "outputId": "3df202c6-b771-4107-b40f-ef4eb64b0a2e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cb10fc6bcea4b1bba6a297590d734f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2dc26f146b95493bb1510596f810ee3c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3092fd4dc5f140f291cbd3d733786042",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbPsAx1I45RQ",
        "outputId": "5e36e524-c941-4750-9499-f2c63848eed3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (input_dropout): Dropout(p=0.2, inplace=False)\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (logit): Linear(in_features=768, out_features=7, bias=True)\n",
              "  (softmax): Softmax(dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "transformer.eval()\n",
        "discriminator.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsPxCOrA45Wp",
        "outputId": "f62b75d6-5ec2-4318-92c4-af4600fe86a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "encoded_dict = tokenizer.encode_plus(\n",
        "                    \"ahmed mohamed kotb\",                     \n",
        "                    add_special_tokens = True, \n",
        "                    max_length = 64,           \n",
        "                    pad_to_max_length = True,\n",
        "                    return_attention_mask = True,   \n",
        "                    return_tensors = 'pt',     \n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnIn1_OJOl8a",
        "outputId": "807b5323-bc53-4e80-a00c-c6036b06110b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:1760: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  input_tensor.shape[chunk_dim] == tensor_shape for input_tensor in input_tensors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "graph(%input_ids : Long(*, *, strides=[64, 1], requires_grad=0, device=cpu),\n",
            "      %attention_mask : Long(*, *, strides=[64, 1], requires_grad=0, device=cpu),\n",
            "      %embeddings.position_ids : Long(1, 512, strides=[512, 1], requires_grad=0, device=cpu),\n",
            "      %embeddings.word_embeddings.weight : Float(28996, 768, strides=[768, 1], requires_grad=1, device=cpu),\n",
            "      %embeddings.position_embeddings.weight : Float(512, 768, strides=[768, 1], requires_grad=1, device=cpu),\n",
            "      %embeddings.token_type_embeddings.weight : Float(2, 768, strides=[768, 1], requires_grad=1, device=cpu),\n",
            "      %embeddings.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %embeddings.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.0.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.0.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.0.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.0.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.0.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.0.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.0.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.0.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.0.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.0.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.1.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.1.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.1.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.1.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.1.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.1.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.1.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.1.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.1.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.1.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.2.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.2.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.2.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.2.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.2.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.2.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.2.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.2.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.2.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.2.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.3.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.3.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.3.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.3.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.3.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.3.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.3.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.3.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.3.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.3.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.4.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.4.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.4.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.4.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.4.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.4.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.4.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.4.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.4.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.4.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.5.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.5.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.5.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.5.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.5.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.5.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.5.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.5.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.5.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.5.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.6.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.6.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.6.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.6.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.6.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.6.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.6.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.6.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.6.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.6.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.7.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.7.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.7.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.7.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.7.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.7.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.7.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.7.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.7.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.7.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.8.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.8.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.8.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.8.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.8.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.8.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.8.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.8.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.8.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.8.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.9.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.9.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.9.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.9.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.9.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.9.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.9.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.9.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.9.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.9.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.10.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.10.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.10.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.10.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.10.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.10.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.10.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.10.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.10.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.10.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.11.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.11.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.11.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.11.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.11.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.11.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.11.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.11.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.11.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %encoder.layer.11.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %pooler.dense.weight : Float(768, 768, strides=[768, 1], requires_grad=1, device=cpu),\n",
            "      %pooler.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %1619 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1620 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1621 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1622 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1623 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1624 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1625 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1626 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1627 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1628 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1629 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1630 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1631 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1632 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1633 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1634 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1635 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1636 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1637 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1638 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1639 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1640 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1641 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1642 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1643 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1644 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1645 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1646 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1647 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1648 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1649 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1650 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1651 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1652 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1653 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1654 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1655 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1656 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1657 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1658 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1659 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1660 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1661 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1662 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1663 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1664 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1665 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1666 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1667 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1668 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1669 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1670 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1671 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1672 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1673 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1674 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1675 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1676 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1677 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1678 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1679 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1680 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1681 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1682 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1683 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1684 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1685 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1686 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1687 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1688 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1689 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1690 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1691 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1692 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1693 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1694 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1695 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1696 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1697 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1698 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1699 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1700 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1701 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1702 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1703 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1704 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1705 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1706 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1707 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1708 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1709 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1710 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1711 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1712 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1713 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1714 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1715 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1716 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1717 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1718 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1719 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1720 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1721 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1722 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1723 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1724 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1725 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1726 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1727 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1728 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1729 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1730 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1731 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1732 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1733 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1734 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1735 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1736 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1737 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1738 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1739 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1740 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1741 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1742 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1743 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1744 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1745 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1746 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1747 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1748 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1749 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1750 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1751 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1752 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1753 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1754 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1755 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1756 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1757 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1758 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1759 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1760 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1761 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1762 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1763 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1764 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1765 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1766 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1767 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1768 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1769 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1770 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1771 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1772 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1773 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1774 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1775 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1776 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu)):\n",
            "  %202 : Long(2, strides=[1], device=cpu) = onnx::Shape(%input_ids)\n",
            "  %203 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %204 : Long(device=cpu) = onnx::Gather[axis=0](%202, %203) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:919:0\n",
            "  %205 : Long(2, strides=[1], device=cpu) = onnx::Shape(%input_ids)\n",
            "  %206 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %207 : Long(device=cpu) = onnx::Gather[axis=0](%205, %206) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:919:0\n",
            "  %208 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%204)\n",
            "  %209 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%207)\n",
            "  %210 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%208, %209)\n",
            "  %211 : Long(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0}](%210) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:935:0\n",
            "  %212 : Long(*, 1, *, strides=[64, 64, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[axes=[1]](%attention_mask) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:258:0\n",
            "  %213 : Long(*, 1, 1, *, strides=[64, 64, 64, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[axes=[2]](%212) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:258:0\n",
            "  %214 : Float(*, 1, 1, *, strides=[64, 64, 64, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1](%213) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:271:0\n",
            "  %215 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %216 : Float(*, 1, 1, *, strides=[64, 64, 64, 1], requires_grad=0, device=cpu) = onnx::Sub(%215, %214) # /usr/local/lib/python3.7/dist-packages/torch/_tensor.py:548:0\n",
            "  %217 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-10000}]()\n",
            "  %218 : Float(*, 1, 1, *, strides=[64, 64, 64, 1], requires_grad=0, device=cpu) = onnx::Mul(%216, %217)\n",
            "  %219 : Long(2, strides=[1], device=cpu) = onnx::Shape(%input_ids)\n",
            "  %220 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %221 : Long(device=cpu) = onnx::Gather[axis=0](%219, %220) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:187:0\n",
            "  %222 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
            "  %223 : Long(requires_grad=0, device=cpu) = onnx::Add(%221, %222)\n",
            "  %227 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%223)\n",
            "  %229 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
            "  %230 : Long(*, *, strides=[512, 1], requires_grad=0, device=cpu) = onnx::Slice(%embeddings.position_ids, %1619, %227, %1620, %229) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:194:0\n",
            "  %231 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Gather(%embeddings.word_embeddings.weight, %input_ids) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2044:0\n",
            "  %232 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Gather(%embeddings.token_type_embeddings.weight, %211) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2044:0\n",
            "  %233 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%231, %232) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:203:0\n",
            "  %234 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Gather(%embeddings.position_embeddings.weight, %230)\n",
            "  %235 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%233, %234) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:206:0\n",
            "  %236 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%235)\n",
            "  %237 : Float(*, *, *, device=cpu) = onnx::Sub(%235, %236)\n",
            "  %238 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %239 : Float(*, *, *, device=cpu) = onnx::Pow(%237, %238)\n",
            "  %240 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%239)\n",
            "  %241 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %242 : Float(*, *, device=cpu) = onnx::Add(%240, %241)\n",
            "  %243 : Float(*, *, device=cpu) = onnx::Sqrt(%242)\n",
            "  %244 : Float(*, *, *, device=cpu) = onnx::Div(%237, %243)\n",
            "  %245 : Float(*, *, *, device=cpu) = onnx::Mul(%244, %embeddings.LayerNorm.weight)\n",
            "  %246 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%245, %embeddings.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %248 : Float(*, *, 768, device=cpu) = onnx::MatMul(%246, %1621)\n",
            "  %249 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.0.attention.self.query.bias, %248) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %251 : Float(*, *, 768, device=cpu) = onnx::MatMul(%246, %1622)\n",
            "  %252 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.0.attention.self.key.bias, %251) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %253 : Long(3, strides=[1], device=cpu) = onnx::Shape(%252)\n",
            "  %254 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %255 : Long(device=cpu) = onnx::Gather[axis=0](%253, %254) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %256 : Long(3, strides=[1], device=cpu) = onnx::Shape(%252)\n",
            "  %257 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %258 : Long(device=cpu) = onnx::Gather[axis=0](%256, %257) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %261 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%255)\n",
            "  %262 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%258)\n",
            "  %265 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%261, %262, %1623, %1624)\n",
            "  %266 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%252, %265) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %268 : Float(*, *, 768, device=cpu) = onnx::MatMul(%246, %1625)\n",
            "  %269 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.0.attention.self.value.bias, %268) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %270 : Long(3, strides=[1], device=cpu) = onnx::Shape(%269)\n",
            "  %271 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %272 : Long(device=cpu) = onnx::Gather[axis=0](%270, %271) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %273 : Long(3, strides=[1], device=cpu) = onnx::Shape(%269)\n",
            "  %274 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %275 : Long(device=cpu) = onnx::Gather[axis=0](%273, %274) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %278 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%272)\n",
            "  %279 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%275)\n",
            "  %282 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%278, %279, %1626, %1627)\n",
            "  %283 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%269, %282) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %284 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%283) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %285 : Long(3, strides=[1], device=cpu) = onnx::Shape(%249)\n",
            "  %286 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %287 : Long(device=cpu) = onnx::Gather[axis=0](%285, %286) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %288 : Long(3, strides=[1], device=cpu) = onnx::Shape(%249)\n",
            "  %289 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %290 : Long(device=cpu) = onnx::Gather[axis=0](%288, %289) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %293 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%287)\n",
            "  %294 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%290)\n",
            "  %297 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%293, %294, %1628, %1629)\n",
            "  %298 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%249, %297) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %299 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%298) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %300 : Float(*, *, *, *, strides=[49152, 64, 1, 768], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%266) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %301 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%299, %300) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %302 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
            "  %303 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Div(%301, %302)\n",
            "  %304 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add(%303, %218) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:311:0\n",
            "  %305 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=3](%304) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %306 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%305, %284) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:324:0\n",
            "  %307 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%306) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:326:0\n",
            "  %308 : Long(4, strides=[1], device=cpu) = onnx::Shape(%307)\n",
            "  %309 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %310 : Long(device=cpu) = onnx::Gather[axis=0](%308, %309) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %311 : Long(4, strides=[1], device=cpu) = onnx::Shape(%307)\n",
            "  %312 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %313 : Long(device=cpu) = onnx::Gather[axis=0](%311, %312) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %315 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%310)\n",
            "  %316 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%313)\n",
            "  %318 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%315, %316, %1630)\n",
            "  %319 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Reshape(%307, %318) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:328:0\n",
            "  %321 : Float(*, *, 768, device=cpu) = onnx::MatMul(%319, %1631)\n",
            "  %322 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.0.attention.output.dense.bias, %321) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %323 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%322, %246) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:347:0\n",
            "  %324 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%323)\n",
            "  %325 : Float(*, *, *, device=cpu) = onnx::Sub(%323, %324)\n",
            "  %326 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %327 : Float(*, *, *, device=cpu) = onnx::Pow(%325, %326)\n",
            "  %328 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%327)\n",
            "  %329 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %330 : Float(*, *, device=cpu) = onnx::Add(%328, %329)\n",
            "  %331 : Float(*, *, device=cpu) = onnx::Sqrt(%330)\n",
            "  %332 : Float(*, *, *, device=cpu) = onnx::Div(%325, %331)\n",
            "  %333 : Float(*, *, *, device=cpu) = onnx::Mul(%332, %encoder.layer.0.attention.output.LayerNorm.weight)\n",
            "  %334 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%333, %encoder.layer.0.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %336 : Float(*, *, 3072, device=cpu) = onnx::MatMul(%334, %1632)\n",
            "  %337 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.0.intermediate.dense.bias, %336) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %338 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %339 : Float(*, *, 3072, device=cpu) = onnx::Div(%337, %338)\n",
            "  %340 : Float(*, *, 3072, device=cpu) = onnx::Erf(%339)\n",
            "  %341 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %342 : Float(*, *, 3072, device=cpu) = onnx::Add(%340, %341)\n",
            "  %343 : Float(*, *, 3072, device=cpu) = onnx::Mul(%337, %342)\n",
            "  %344 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %345 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Mul(%343, %344) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1556:0\n",
            "  %347 : Float(*, *, 768, device=cpu) = onnx::MatMul(%345, %1633)\n",
            "  %348 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.0.output.dense.bias, %347) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %349 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%348, %334) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:425:0\n",
            "  %350 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%349)\n",
            "  %351 : Float(*, *, *, device=cpu) = onnx::Sub(%349, %350)\n",
            "  %352 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %353 : Float(*, *, *, device=cpu) = onnx::Pow(%351, %352)\n",
            "  %354 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%353)\n",
            "  %355 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %356 : Float(*, *, device=cpu) = onnx::Add(%354, %355)\n",
            "  %357 : Float(*, *, device=cpu) = onnx::Sqrt(%356)\n",
            "  %358 : Float(*, *, *, device=cpu) = onnx::Div(%351, %357)\n",
            "  %359 : Float(*, *, *, device=cpu) = onnx::Mul(%358, %encoder.layer.0.output.LayerNorm.weight)\n",
            "  %360 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%359, %encoder.layer.0.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %362 : Float(*, *, 768, device=cpu) = onnx::MatMul(%360, %1634)\n",
            "  %363 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.1.attention.self.query.bias, %362) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %365 : Float(*, *, 768, device=cpu) = onnx::MatMul(%360, %1635)\n",
            "  %366 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.1.attention.self.key.bias, %365) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %367 : Long(3, strides=[1], device=cpu) = onnx::Shape(%366)\n",
            "  %368 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %369 : Long(device=cpu) = onnx::Gather[axis=0](%367, %368) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %370 : Long(3, strides=[1], device=cpu) = onnx::Shape(%366)\n",
            "  %371 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %372 : Long(device=cpu) = onnx::Gather[axis=0](%370, %371) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %375 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%369)\n",
            "  %376 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%372)\n",
            "  %379 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%375, %376, %1636, %1637)\n",
            "  %380 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%366, %379) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %382 : Float(*, *, 768, device=cpu) = onnx::MatMul(%360, %1638)\n",
            "  %383 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.1.attention.self.value.bias, %382) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %384 : Long(3, strides=[1], device=cpu) = onnx::Shape(%383)\n",
            "  %385 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %386 : Long(device=cpu) = onnx::Gather[axis=0](%384, %385) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %387 : Long(3, strides=[1], device=cpu) = onnx::Shape(%383)\n",
            "  %388 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %389 : Long(device=cpu) = onnx::Gather[axis=0](%387, %388) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %392 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%386)\n",
            "  %393 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%389)\n",
            "  %396 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%392, %393, %1639, %1640)\n",
            "  %397 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%383, %396) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %398 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%397) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %399 : Long(3, strides=[1], device=cpu) = onnx::Shape(%363)\n",
            "  %400 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %401 : Long(device=cpu) = onnx::Gather[axis=0](%399, %400) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %402 : Long(3, strides=[1], device=cpu) = onnx::Shape(%363)\n",
            "  %403 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %404 : Long(device=cpu) = onnx::Gather[axis=0](%402, %403) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %407 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%401)\n",
            "  %408 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%404)\n",
            "  %411 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%407, %408, %1641, %1642)\n",
            "  %412 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%363, %411) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %413 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%412) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %414 : Float(*, *, *, *, strides=[49152, 64, 1, 768], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%380) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %415 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%413, %414) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %416 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
            "  %417 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Div(%415, %416)\n",
            "  %418 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add(%417, %218) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:311:0\n",
            "  %419 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=3](%418) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %420 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%419, %398) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:324:0\n",
            "  %421 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%420) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:326:0\n",
            "  %422 : Long(4, strides=[1], device=cpu) = onnx::Shape(%421)\n",
            "  %423 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %424 : Long(device=cpu) = onnx::Gather[axis=0](%422, %423) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %425 : Long(4, strides=[1], device=cpu) = onnx::Shape(%421)\n",
            "  %426 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %427 : Long(device=cpu) = onnx::Gather[axis=0](%425, %426) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %429 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%424)\n",
            "  %430 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%427)\n",
            "  %432 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%429, %430, %1643)\n",
            "  %433 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Reshape(%421, %432) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:328:0\n",
            "  %435 : Float(*, *, 768, device=cpu) = onnx::MatMul(%433, %1644)\n",
            "  %436 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.1.attention.output.dense.bias, %435) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %437 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%436, %360) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:347:0\n",
            "  %438 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%437)\n",
            "  %439 : Float(*, *, *, device=cpu) = onnx::Sub(%437, %438)\n",
            "  %440 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %441 : Float(*, *, *, device=cpu) = onnx::Pow(%439, %440)\n",
            "  %442 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%441)\n",
            "  %443 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %444 : Float(*, *, device=cpu) = onnx::Add(%442, %443)\n",
            "  %445 : Float(*, *, device=cpu) = onnx::Sqrt(%444)\n",
            "  %446 : Float(*, *, *, device=cpu) = onnx::Div(%439, %445)\n",
            "  %447 : Float(*, *, *, device=cpu) = onnx::Mul(%446, %encoder.layer.1.attention.output.LayerNorm.weight)\n",
            "  %448 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%447, %encoder.layer.1.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %450 : Float(*, *, 3072, device=cpu) = onnx::MatMul(%448, %1645)\n",
            "  %451 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.1.intermediate.dense.bias, %450) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %452 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %453 : Float(*, *, 3072, device=cpu) = onnx::Div(%451, %452)\n",
            "  %454 : Float(*, *, 3072, device=cpu) = onnx::Erf(%453)\n",
            "  %455 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %456 : Float(*, *, 3072, device=cpu) = onnx::Add(%454, %455)\n",
            "  %457 : Float(*, *, 3072, device=cpu) = onnx::Mul(%451, %456)\n",
            "  %458 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %459 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Mul(%457, %458) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1556:0\n",
            "  %461 : Float(*, *, 768, device=cpu) = onnx::MatMul(%459, %1646)\n",
            "  %462 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.1.output.dense.bias, %461) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %463 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%462, %448) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:425:0\n",
            "  %464 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%463)\n",
            "  %465 : Float(*, *, *, device=cpu) = onnx::Sub(%463, %464)\n",
            "  %466 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %467 : Float(*, *, *, device=cpu) = onnx::Pow(%465, %466)\n",
            "  %468 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%467)\n",
            "  %469 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %470 : Float(*, *, device=cpu) = onnx::Add(%468, %469)\n",
            "  %471 : Float(*, *, device=cpu) = onnx::Sqrt(%470)\n",
            "  %472 : Float(*, *, *, device=cpu) = onnx::Div(%465, %471)\n",
            "  %473 : Float(*, *, *, device=cpu) = onnx::Mul(%472, %encoder.layer.1.output.LayerNorm.weight)\n",
            "  %474 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%473, %encoder.layer.1.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %476 : Float(*, *, 768, device=cpu) = onnx::MatMul(%474, %1647)\n",
            "  %477 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.2.attention.self.query.bias, %476) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %479 : Float(*, *, 768, device=cpu) = onnx::MatMul(%474, %1648)\n",
            "  %480 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.2.attention.self.key.bias, %479) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %481 : Long(3, strides=[1], device=cpu) = onnx::Shape(%480)\n",
            "  %482 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %483 : Long(device=cpu) = onnx::Gather[axis=0](%481, %482) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %484 : Long(3, strides=[1], device=cpu) = onnx::Shape(%480)\n",
            "  %485 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %486 : Long(device=cpu) = onnx::Gather[axis=0](%484, %485) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %489 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%483)\n",
            "  %490 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%486)\n",
            "  %493 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%489, %490, %1649, %1650)\n",
            "  %494 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%480, %493) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %496 : Float(*, *, 768, device=cpu) = onnx::MatMul(%474, %1651)\n",
            "  %497 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.2.attention.self.value.bias, %496) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %498 : Long(3, strides=[1], device=cpu) = onnx::Shape(%497)\n",
            "  %499 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %500 : Long(device=cpu) = onnx::Gather[axis=0](%498, %499) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %501 : Long(3, strides=[1], device=cpu) = onnx::Shape(%497)\n",
            "  %502 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %503 : Long(device=cpu) = onnx::Gather[axis=0](%501, %502) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %506 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%500)\n",
            "  %507 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%503)\n",
            "  %510 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%506, %507, %1652, %1653)\n",
            "  %511 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%497, %510) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %512 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%511) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %513 : Long(3, strides=[1], device=cpu) = onnx::Shape(%477)\n",
            "  %514 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %515 : Long(device=cpu) = onnx::Gather[axis=0](%513, %514) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %516 : Long(3, strides=[1], device=cpu) = onnx::Shape(%477)\n",
            "  %517 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %518 : Long(device=cpu) = onnx::Gather[axis=0](%516, %517) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %521 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%515)\n",
            "  %522 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%518)\n",
            "  %525 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%521, %522, %1654, %1655)\n",
            "  %526 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%477, %525) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %527 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%526) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %528 : Float(*, *, *, *, strides=[49152, 64, 1, 768], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%494) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %529 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%527, %528) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %530 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
            "  %531 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Div(%529, %530)\n",
            "  %532 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add(%531, %218) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:311:0\n",
            "  %533 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=3](%532) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %534 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%533, %512) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:324:0\n",
            "  %535 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%534) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:326:0\n",
            "  %536 : Long(4, strides=[1], device=cpu) = onnx::Shape(%535)\n",
            "  %537 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %538 : Long(device=cpu) = onnx::Gather[axis=0](%536, %537) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %539 : Long(4, strides=[1], device=cpu) = onnx::Shape(%535)\n",
            "  %540 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %541 : Long(device=cpu) = onnx::Gather[axis=0](%539, %540) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %543 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%538)\n",
            "  %544 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%541)\n",
            "  %546 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%543, %544, %1656)\n",
            "  %547 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Reshape(%535, %546) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:328:0\n",
            "  %549 : Float(*, *, 768, device=cpu) = onnx::MatMul(%547, %1657)\n",
            "  %550 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.2.attention.output.dense.bias, %549) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %551 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%550, %474) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:347:0\n",
            "  %552 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%551)\n",
            "  %553 : Float(*, *, *, device=cpu) = onnx::Sub(%551, %552)\n",
            "  %554 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %555 : Float(*, *, *, device=cpu) = onnx::Pow(%553, %554)\n",
            "  %556 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%555)\n",
            "  %557 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %558 : Float(*, *, device=cpu) = onnx::Add(%556, %557)\n",
            "  %559 : Float(*, *, device=cpu) = onnx::Sqrt(%558)\n",
            "  %560 : Float(*, *, *, device=cpu) = onnx::Div(%553, %559)\n",
            "  %561 : Float(*, *, *, device=cpu) = onnx::Mul(%560, %encoder.layer.2.attention.output.LayerNorm.weight)\n",
            "  %562 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%561, %encoder.layer.2.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %564 : Float(*, *, 3072, device=cpu) = onnx::MatMul(%562, %1658)\n",
            "  %565 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.2.intermediate.dense.bias, %564) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %566 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %567 : Float(*, *, 3072, device=cpu) = onnx::Div(%565, %566)\n",
            "  %568 : Float(*, *, 3072, device=cpu) = onnx::Erf(%567)\n",
            "  %569 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %570 : Float(*, *, 3072, device=cpu) = onnx::Add(%568, %569)\n",
            "  %571 : Float(*, *, 3072, device=cpu) = onnx::Mul(%565, %570)\n",
            "  %572 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %573 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Mul(%571, %572) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1556:0\n",
            "  %575 : Float(*, *, 768, device=cpu) = onnx::MatMul(%573, %1659)\n",
            "  %576 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.2.output.dense.bias, %575) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %577 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%576, %562) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:425:0\n",
            "  %578 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%577)\n",
            "  %579 : Float(*, *, *, device=cpu) = onnx::Sub(%577, %578)\n",
            "  %580 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %581 : Float(*, *, *, device=cpu) = onnx::Pow(%579, %580)\n",
            "  %582 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%581)\n",
            "  %583 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %584 : Float(*, *, device=cpu) = onnx::Add(%582, %583)\n",
            "  %585 : Float(*, *, device=cpu) = onnx::Sqrt(%584)\n",
            "  %586 : Float(*, *, *, device=cpu) = onnx::Div(%579, %585)\n",
            "  %587 : Float(*, *, *, device=cpu) = onnx::Mul(%586, %encoder.layer.2.output.LayerNorm.weight)\n",
            "  %588 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%587, %encoder.layer.2.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %590 : Float(*, *, 768, device=cpu) = onnx::MatMul(%588, %1660)\n",
            "  %591 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.3.attention.self.query.bias, %590) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %593 : Float(*, *, 768, device=cpu) = onnx::MatMul(%588, %1661)\n",
            "  %594 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.3.attention.self.key.bias, %593) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %595 : Long(3, strides=[1], device=cpu) = onnx::Shape(%594)\n",
            "  %596 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %597 : Long(device=cpu) = onnx::Gather[axis=0](%595, %596) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %598 : Long(3, strides=[1], device=cpu) = onnx::Shape(%594)\n",
            "  %599 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %600 : Long(device=cpu) = onnx::Gather[axis=0](%598, %599) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %603 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%597)\n",
            "  %604 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%600)\n",
            "  %607 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%603, %604, %1662, %1663)\n",
            "  %608 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%594, %607) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %610 : Float(*, *, 768, device=cpu) = onnx::MatMul(%588, %1664)\n",
            "  %611 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.3.attention.self.value.bias, %610) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %612 : Long(3, strides=[1], device=cpu) = onnx::Shape(%611)\n",
            "  %613 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %614 : Long(device=cpu) = onnx::Gather[axis=0](%612, %613) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %615 : Long(3, strides=[1], device=cpu) = onnx::Shape(%611)\n",
            "  %616 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %617 : Long(device=cpu) = onnx::Gather[axis=0](%615, %616) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %620 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%614)\n",
            "  %621 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%617)\n",
            "  %624 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%620, %621, %1665, %1666)\n",
            "  %625 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%611, %624) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %626 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%625) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %627 : Long(3, strides=[1], device=cpu) = onnx::Shape(%591)\n",
            "  %628 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %629 : Long(device=cpu) = onnx::Gather[axis=0](%627, %628) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %630 : Long(3, strides=[1], device=cpu) = onnx::Shape(%591)\n",
            "  %631 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %632 : Long(device=cpu) = onnx::Gather[axis=0](%630, %631) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %635 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%629)\n",
            "  %636 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%632)\n",
            "  %639 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%635, %636, %1667, %1668)\n",
            "  %640 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%591, %639) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %641 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%640) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %642 : Float(*, *, *, *, strides=[49152, 64, 1, 768], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%608) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %643 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%641, %642) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %644 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
            "  %645 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Div(%643, %644)\n",
            "  %646 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add(%645, %218) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:311:0\n",
            "  %647 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=3](%646) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %648 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%647, %626) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:324:0\n",
            "  %649 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%648) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:326:0\n",
            "  %650 : Long(4, strides=[1], device=cpu) = onnx::Shape(%649)\n",
            "  %651 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %652 : Long(device=cpu) = onnx::Gather[axis=0](%650, %651) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %653 : Long(4, strides=[1], device=cpu) = onnx::Shape(%649)\n",
            "  %654 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %655 : Long(device=cpu) = onnx::Gather[axis=0](%653, %654) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %657 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%652)\n",
            "  %658 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%655)\n",
            "  %660 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%657, %658, %1669)\n",
            "  %661 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Reshape(%649, %660) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:328:0\n",
            "  %663 : Float(*, *, 768, device=cpu) = onnx::MatMul(%661, %1670)\n",
            "  %664 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.3.attention.output.dense.bias, %663) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %665 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%664, %588) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:347:0\n",
            "  %666 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%665)\n",
            "  %667 : Float(*, *, *, device=cpu) = onnx::Sub(%665, %666)\n",
            "  %668 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %669 : Float(*, *, *, device=cpu) = onnx::Pow(%667, %668)\n",
            "  %670 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%669)\n",
            "  %671 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %672 : Float(*, *, device=cpu) = onnx::Add(%670, %671)\n",
            "  %673 : Float(*, *, device=cpu) = onnx::Sqrt(%672)\n",
            "  %674 : Float(*, *, *, device=cpu) = onnx::Div(%667, %673)\n",
            "  %675 : Float(*, *, *, device=cpu) = onnx::Mul(%674, %encoder.layer.3.attention.output.LayerNorm.weight)\n",
            "  %676 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%675, %encoder.layer.3.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %678 : Float(*, *, 3072, device=cpu) = onnx::MatMul(%676, %1671)\n",
            "  %679 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.3.intermediate.dense.bias, %678) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %680 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %681 : Float(*, *, 3072, device=cpu) = onnx::Div(%679, %680)\n",
            "  %682 : Float(*, *, 3072, device=cpu) = onnx::Erf(%681)\n",
            "  %683 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %684 : Float(*, *, 3072, device=cpu) = onnx::Add(%682, %683)\n",
            "  %685 : Float(*, *, 3072, device=cpu) = onnx::Mul(%679, %684)\n",
            "  %686 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %687 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Mul(%685, %686) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1556:0\n",
            "  %689 : Float(*, *, 768, device=cpu) = onnx::MatMul(%687, %1672)\n",
            "  %690 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.3.output.dense.bias, %689) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %691 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%690, %676) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:425:0\n",
            "  %692 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%691)\n",
            "  %693 : Float(*, *, *, device=cpu) = onnx::Sub(%691, %692)\n",
            "  %694 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %695 : Float(*, *, *, device=cpu) = onnx::Pow(%693, %694)\n",
            "  %696 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%695)\n",
            "  %697 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %698 : Float(*, *, device=cpu) = onnx::Add(%696, %697)\n",
            "  %699 : Float(*, *, device=cpu) = onnx::Sqrt(%698)\n",
            "  %700 : Float(*, *, *, device=cpu) = onnx::Div(%693, %699)\n",
            "  %701 : Float(*, *, *, device=cpu) = onnx::Mul(%700, %encoder.layer.3.output.LayerNorm.weight)\n",
            "  %702 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%701, %encoder.layer.3.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %704 : Float(*, *, 768, device=cpu) = onnx::MatMul(%702, %1673)\n",
            "  %705 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.4.attention.self.query.bias, %704) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %707 : Float(*, *, 768, device=cpu) = onnx::MatMul(%702, %1674)\n",
            "  %708 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.4.attention.self.key.bias, %707) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %709 : Long(3, strides=[1], device=cpu) = onnx::Shape(%708)\n",
            "  %710 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %711 : Long(device=cpu) = onnx::Gather[axis=0](%709, %710) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %712 : Long(3, strides=[1], device=cpu) = onnx::Shape(%708)\n",
            "  %713 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %714 : Long(device=cpu) = onnx::Gather[axis=0](%712, %713) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %717 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%711)\n",
            "  %718 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%714)\n",
            "  %721 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%717, %718, %1675, %1676)\n",
            "  %722 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%708, %721) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %724 : Float(*, *, 768, device=cpu) = onnx::MatMul(%702, %1677)\n",
            "  %725 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.4.attention.self.value.bias, %724) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %726 : Long(3, strides=[1], device=cpu) = onnx::Shape(%725)\n",
            "  %727 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %728 : Long(device=cpu) = onnx::Gather[axis=0](%726, %727) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %729 : Long(3, strides=[1], device=cpu) = onnx::Shape(%725)\n",
            "  %730 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %731 : Long(device=cpu) = onnx::Gather[axis=0](%729, %730) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %734 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%728)\n",
            "  %735 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%731)\n",
            "  %738 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%734, %735, %1678, %1679)\n",
            "  %739 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%725, %738) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %740 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%739) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %741 : Long(3, strides=[1], device=cpu) = onnx::Shape(%705)\n",
            "  %742 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %743 : Long(device=cpu) = onnx::Gather[axis=0](%741, %742) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %744 : Long(3, strides=[1], device=cpu) = onnx::Shape(%705)\n",
            "  %745 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %746 : Long(device=cpu) = onnx::Gather[axis=0](%744, %745) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %749 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%743)\n",
            "  %750 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%746)\n",
            "  %753 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%749, %750, %1680, %1681)\n",
            "  %754 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%705, %753) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %755 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%754) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %756 : Float(*, *, *, *, strides=[49152, 64, 1, 768], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%722) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %757 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%755, %756) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %758 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
            "  %759 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Div(%757, %758)\n",
            "  %760 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add(%759, %218) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:311:0\n",
            "  %761 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=3](%760) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %762 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%761, %740) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:324:0\n",
            "  %763 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%762) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:326:0\n",
            "  %764 : Long(4, strides=[1], device=cpu) = onnx::Shape(%763)\n",
            "  %765 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %766 : Long(device=cpu) = onnx::Gather[axis=0](%764, %765) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %767 : Long(4, strides=[1], device=cpu) = onnx::Shape(%763)\n",
            "  %768 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %769 : Long(device=cpu) = onnx::Gather[axis=0](%767, %768) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %771 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%766)\n",
            "  %772 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%769)\n",
            "  %774 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%771, %772, %1682)\n",
            "  %775 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Reshape(%763, %774) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:328:0\n",
            "  %777 : Float(*, *, 768, device=cpu) = onnx::MatMul(%775, %1683)\n",
            "  %778 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.4.attention.output.dense.bias, %777) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %779 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%778, %702) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:347:0\n",
            "  %780 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%779)\n",
            "  %781 : Float(*, *, *, device=cpu) = onnx::Sub(%779, %780)\n",
            "  %782 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %783 : Float(*, *, *, device=cpu) = onnx::Pow(%781, %782)\n",
            "  %784 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%783)\n",
            "  %785 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %786 : Float(*, *, device=cpu) = onnx::Add(%784, %785)\n",
            "  %787 : Float(*, *, device=cpu) = onnx::Sqrt(%786)\n",
            "  %788 : Float(*, *, *, device=cpu) = onnx::Div(%781, %787)\n",
            "  %789 : Float(*, *, *, device=cpu) = onnx::Mul(%788, %encoder.layer.4.attention.output.LayerNorm.weight)\n",
            "  %790 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%789, %encoder.layer.4.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %792 : Float(*, *, 3072, device=cpu) = onnx::MatMul(%790, %1684)\n",
            "  %793 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.4.intermediate.dense.bias, %792) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %794 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %795 : Float(*, *, 3072, device=cpu) = onnx::Div(%793, %794)\n",
            "  %796 : Float(*, *, 3072, device=cpu) = onnx::Erf(%795)\n",
            "  %797 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %798 : Float(*, *, 3072, device=cpu) = onnx::Add(%796, %797)\n",
            "  %799 : Float(*, *, 3072, device=cpu) = onnx::Mul(%793, %798)\n",
            "  %800 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %801 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Mul(%799, %800) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1556:0\n",
            "  %803 : Float(*, *, 768, device=cpu) = onnx::MatMul(%801, %1685)\n",
            "  %804 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.4.output.dense.bias, %803) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %805 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%804, %790) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:425:0\n",
            "  %806 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%805)\n",
            "  %807 : Float(*, *, *, device=cpu) = onnx::Sub(%805, %806)\n",
            "  %808 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %809 : Float(*, *, *, device=cpu) = onnx::Pow(%807, %808)\n",
            "  %810 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%809)\n",
            "  %811 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %812 : Float(*, *, device=cpu) = onnx::Add(%810, %811)\n",
            "  %813 : Float(*, *, device=cpu) = onnx::Sqrt(%812)\n",
            "  %814 : Float(*, *, *, device=cpu) = onnx::Div(%807, %813)\n",
            "  %815 : Float(*, *, *, device=cpu) = onnx::Mul(%814, %encoder.layer.4.output.LayerNorm.weight)\n",
            "  %816 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%815, %encoder.layer.4.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %818 : Float(*, *, 768, device=cpu) = onnx::MatMul(%816, %1686)\n",
            "  %819 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.5.attention.self.query.bias, %818) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %821 : Float(*, *, 768, device=cpu) = onnx::MatMul(%816, %1687)\n",
            "  %822 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.5.attention.self.key.bias, %821) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %823 : Long(3, strides=[1], device=cpu) = onnx::Shape(%822)\n",
            "  %824 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %825 : Long(device=cpu) = onnx::Gather[axis=0](%823, %824) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %826 : Long(3, strides=[1], device=cpu) = onnx::Shape(%822)\n",
            "  %827 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %828 : Long(device=cpu) = onnx::Gather[axis=0](%826, %827) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %831 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%825)\n",
            "  %832 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%828)\n",
            "  %835 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%831, %832, %1688, %1689)\n",
            "  %836 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%822, %835) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %838 : Float(*, *, 768, device=cpu) = onnx::MatMul(%816, %1690)\n",
            "  %839 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.5.attention.self.value.bias, %838) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %840 : Long(3, strides=[1], device=cpu) = onnx::Shape(%839)\n",
            "  %841 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %842 : Long(device=cpu) = onnx::Gather[axis=0](%840, %841) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %843 : Long(3, strides=[1], device=cpu) = onnx::Shape(%839)\n",
            "  %844 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %845 : Long(device=cpu) = onnx::Gather[axis=0](%843, %844) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %848 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%842)\n",
            "  %849 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%845)\n",
            "  %852 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%848, %849, %1691, %1692)\n",
            "  %853 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%839, %852) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %854 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%853) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %855 : Long(3, strides=[1], device=cpu) = onnx::Shape(%819)\n",
            "  %856 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %857 : Long(device=cpu) = onnx::Gather[axis=0](%855, %856) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %858 : Long(3, strides=[1], device=cpu) = onnx::Shape(%819)\n",
            "  %859 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %860 : Long(device=cpu) = onnx::Gather[axis=0](%858, %859) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %863 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%857)\n",
            "  %864 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%860)\n",
            "  %867 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%863, %864, %1693, %1694)\n",
            "  %868 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%819, %867) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %869 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%868) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %870 : Float(*, *, *, *, strides=[49152, 64, 1, 768], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%836) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %871 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%869, %870) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %872 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
            "  %873 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Div(%871, %872)\n",
            "  %874 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add(%873, %218) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:311:0\n",
            "  %875 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=3](%874) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %876 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%875, %854) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:324:0\n",
            "  %877 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%876) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:326:0\n",
            "  %878 : Long(4, strides=[1], device=cpu) = onnx::Shape(%877)\n",
            "  %879 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %880 : Long(device=cpu) = onnx::Gather[axis=0](%878, %879) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %881 : Long(4, strides=[1], device=cpu) = onnx::Shape(%877)\n",
            "  %882 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %883 : Long(device=cpu) = onnx::Gather[axis=0](%881, %882) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %885 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%880)\n",
            "  %886 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%883)\n",
            "  %888 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%885, %886, %1695)\n",
            "  %889 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Reshape(%877, %888) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:328:0\n",
            "  %891 : Float(*, *, 768, device=cpu) = onnx::MatMul(%889, %1696)\n",
            "  %892 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.5.attention.output.dense.bias, %891) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %893 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%892, %816) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:347:0\n",
            "  %894 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%893)\n",
            "  %895 : Float(*, *, *, device=cpu) = onnx::Sub(%893, %894)\n",
            "  %896 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %897 : Float(*, *, *, device=cpu) = onnx::Pow(%895, %896)\n",
            "  %898 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%897)\n",
            "  %899 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %900 : Float(*, *, device=cpu) = onnx::Add(%898, %899)\n",
            "  %901 : Float(*, *, device=cpu) = onnx::Sqrt(%900)\n",
            "  %902 : Float(*, *, *, device=cpu) = onnx::Div(%895, %901)\n",
            "  %903 : Float(*, *, *, device=cpu) = onnx::Mul(%902, %encoder.layer.5.attention.output.LayerNorm.weight)\n",
            "  %904 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%903, %encoder.layer.5.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %906 : Float(*, *, 3072, device=cpu) = onnx::MatMul(%904, %1697)\n",
            "  %907 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.5.intermediate.dense.bias, %906) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %908 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %909 : Float(*, *, 3072, device=cpu) = onnx::Div(%907, %908)\n",
            "  %910 : Float(*, *, 3072, device=cpu) = onnx::Erf(%909)\n",
            "  %911 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %912 : Float(*, *, 3072, device=cpu) = onnx::Add(%910, %911)\n",
            "  %913 : Float(*, *, 3072, device=cpu) = onnx::Mul(%907, %912)\n",
            "  %914 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %915 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Mul(%913, %914) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1556:0\n",
            "  %917 : Float(*, *, 768, device=cpu) = onnx::MatMul(%915, %1698)\n",
            "  %918 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.5.output.dense.bias, %917) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %919 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%918, %904) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:425:0\n",
            "  %920 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%919)\n",
            "  %921 : Float(*, *, *, device=cpu) = onnx::Sub(%919, %920)\n",
            "  %922 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %923 : Float(*, *, *, device=cpu) = onnx::Pow(%921, %922)\n",
            "  %924 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%923)\n",
            "  %925 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %926 : Float(*, *, device=cpu) = onnx::Add(%924, %925)\n",
            "  %927 : Float(*, *, device=cpu) = onnx::Sqrt(%926)\n",
            "  %928 : Float(*, *, *, device=cpu) = onnx::Div(%921, %927)\n",
            "  %929 : Float(*, *, *, device=cpu) = onnx::Mul(%928, %encoder.layer.5.output.LayerNorm.weight)\n",
            "  %930 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%929, %encoder.layer.5.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %932 : Float(*, *, 768, device=cpu) = onnx::MatMul(%930, %1699)\n",
            "  %933 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.6.attention.self.query.bias, %932) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %935 : Float(*, *, 768, device=cpu) = onnx::MatMul(%930, %1700)\n",
            "  %936 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.6.attention.self.key.bias, %935) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %937 : Long(3, strides=[1], device=cpu) = onnx::Shape(%936)\n",
            "  %938 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %939 : Long(device=cpu) = onnx::Gather[axis=0](%937, %938) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %940 : Long(3, strides=[1], device=cpu) = onnx::Shape(%936)\n",
            "  %941 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %942 : Long(device=cpu) = onnx::Gather[axis=0](%940, %941) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %945 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%939)\n",
            "  %946 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%942)\n",
            "  %949 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%945, %946, %1701, %1702)\n",
            "  %950 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%936, %949) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %952 : Float(*, *, 768, device=cpu) = onnx::MatMul(%930, %1703)\n",
            "  %953 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.6.attention.self.value.bias, %952) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %954 : Long(3, strides=[1], device=cpu) = onnx::Shape(%953)\n",
            "  %955 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %956 : Long(device=cpu) = onnx::Gather[axis=0](%954, %955) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %957 : Long(3, strides=[1], device=cpu) = onnx::Shape(%953)\n",
            "  %958 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %959 : Long(device=cpu) = onnx::Gather[axis=0](%957, %958) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %962 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%956)\n",
            "  %963 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%959)\n",
            "  %966 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%962, %963, %1704, %1705)\n",
            "  %967 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%953, %966) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %968 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%967) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %969 : Long(3, strides=[1], device=cpu) = onnx::Shape(%933)\n",
            "  %970 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %971 : Long(device=cpu) = onnx::Gather[axis=0](%969, %970) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %972 : Long(3, strides=[1], device=cpu) = onnx::Shape(%933)\n",
            "  %973 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %974 : Long(device=cpu) = onnx::Gather[axis=0](%972, %973) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %977 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%971)\n",
            "  %978 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%974)\n",
            "  %981 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%977, %978, %1706, %1707)\n",
            "  %982 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%933, %981) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %983 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%982) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %984 : Float(*, *, *, *, strides=[49152, 64, 1, 768], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%950) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %985 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%983, %984) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %986 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
            "  %987 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Div(%985, %986)\n",
            "  %988 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add(%987, %218) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:311:0\n",
            "  %989 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=3](%988) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %990 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%989, %968) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:324:0\n",
            "  %991 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%990) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:326:0\n",
            "  %992 : Long(4, strides=[1], device=cpu) = onnx::Shape(%991)\n",
            "  %993 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %994 : Long(device=cpu) = onnx::Gather[axis=0](%992, %993) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %995 : Long(4, strides=[1], device=cpu) = onnx::Shape(%991)\n",
            "  %996 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %997 : Long(device=cpu) = onnx::Gather[axis=0](%995, %996) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %999 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%994)\n",
            "  %1000 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%997)\n",
            "  %1002 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%999, %1000, %1708)\n",
            "  %1003 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Reshape(%991, %1002) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:328:0\n",
            "  %1005 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1003, %1709)\n",
            "  %1006 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.6.attention.output.dense.bias, %1005) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %1007 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1006, %930) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:347:0\n",
            "  %1008 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1007)\n",
            "  %1009 : Float(*, *, *, device=cpu) = onnx::Sub(%1007, %1008)\n",
            "  %1010 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1011 : Float(*, *, *, device=cpu) = onnx::Pow(%1009, %1010)\n",
            "  %1012 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1011)\n",
            "  %1013 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1014 : Float(*, *, device=cpu) = onnx::Add(%1012, %1013)\n",
            "  %1015 : Float(*, *, device=cpu) = onnx::Sqrt(%1014)\n",
            "  %1016 : Float(*, *, *, device=cpu) = onnx::Div(%1009, %1015)\n",
            "  %1017 : Float(*, *, *, device=cpu) = onnx::Mul(%1016, %encoder.layer.6.attention.output.LayerNorm.weight)\n",
            "  %1018 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1017, %encoder.layer.6.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %1020 : Float(*, *, 3072, device=cpu) = onnx::MatMul(%1018, %1710)\n",
            "  %1021 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.6.intermediate.dense.bias, %1020) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1022 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %1023 : Float(*, *, 3072, device=cpu) = onnx::Div(%1021, %1022)\n",
            "  %1024 : Float(*, *, 3072, device=cpu) = onnx::Erf(%1023)\n",
            "  %1025 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1026 : Float(*, *, 3072, device=cpu) = onnx::Add(%1024, %1025)\n",
            "  %1027 : Float(*, *, 3072, device=cpu) = onnx::Mul(%1021, %1026)\n",
            "  %1028 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %1029 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Mul(%1027, %1028) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1556:0\n",
            "  %1031 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1029, %1711)\n",
            "  %1032 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.6.output.dense.bias, %1031) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %1033 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1032, %1018) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:425:0\n",
            "  %1034 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1033)\n",
            "  %1035 : Float(*, *, *, device=cpu) = onnx::Sub(%1033, %1034)\n",
            "  %1036 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1037 : Float(*, *, *, device=cpu) = onnx::Pow(%1035, %1036)\n",
            "  %1038 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1037)\n",
            "  %1039 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1040 : Float(*, *, device=cpu) = onnx::Add(%1038, %1039)\n",
            "  %1041 : Float(*, *, device=cpu) = onnx::Sqrt(%1040)\n",
            "  %1042 : Float(*, *, *, device=cpu) = onnx::Div(%1035, %1041)\n",
            "  %1043 : Float(*, *, *, device=cpu) = onnx::Mul(%1042, %encoder.layer.6.output.LayerNorm.weight)\n",
            "  %1044 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1043, %encoder.layer.6.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %1046 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1044, %1712)\n",
            "  %1047 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.7.attention.self.query.bias, %1046) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1049 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1044, %1713)\n",
            "  %1050 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.7.attention.self.key.bias, %1049) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1051 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1050)\n",
            "  %1052 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1053 : Long(device=cpu) = onnx::Gather[axis=0](%1051, %1052) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1054 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1050)\n",
            "  %1055 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1056 : Long(device=cpu) = onnx::Gather[axis=0](%1054, %1055) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1059 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1053)\n",
            "  %1060 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1056)\n",
            "  %1063 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1059, %1060, %1714, %1715)\n",
            "  %1064 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1050, %1063) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %1066 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1044, %1716)\n",
            "  %1067 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.7.attention.self.value.bias, %1066) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1068 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1067)\n",
            "  %1069 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1070 : Long(device=cpu) = onnx::Gather[axis=0](%1068, %1069) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1071 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1067)\n",
            "  %1072 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1073 : Long(device=cpu) = onnx::Gather[axis=0](%1071, %1072) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1076 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1070)\n",
            "  %1077 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1073)\n",
            "  %1080 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1076, %1077, %1717, %1718)\n",
            "  %1081 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1067, %1080) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %1082 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1081) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %1083 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1047)\n",
            "  %1084 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1085 : Long(device=cpu) = onnx::Gather[axis=0](%1083, %1084) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1086 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1047)\n",
            "  %1087 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1088 : Long(device=cpu) = onnx::Gather[axis=0](%1086, %1087) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1091 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1085)\n",
            "  %1092 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1088)\n",
            "  %1095 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1091, %1092, %1719, %1720)\n",
            "  %1096 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1047, %1095) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %1097 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1096) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %1098 : Float(*, *, *, *, strides=[49152, 64, 1, 768], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%1064) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %1099 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%1097, %1098) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %1100 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
            "  %1101 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Div(%1099, %1100)\n",
            "  %1102 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add(%1101, %218) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:311:0\n",
            "  %1103 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=3](%1102) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %1104 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%1103, %1082) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:324:0\n",
            "  %1105 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1104) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:326:0\n",
            "  %1106 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1105)\n",
            "  %1107 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1108 : Long(device=cpu) = onnx::Gather[axis=0](%1106, %1107) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %1109 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1105)\n",
            "  %1110 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1111 : Long(device=cpu) = onnx::Gather[axis=0](%1109, %1110) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %1113 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1108)\n",
            "  %1114 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1111)\n",
            "  %1116 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1113, %1114, %1721)\n",
            "  %1117 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1105, %1116) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:328:0\n",
            "  %1119 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1117, %1722)\n",
            "  %1120 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.7.attention.output.dense.bias, %1119) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %1121 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1120, %1044) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:347:0\n",
            "  %1122 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1121)\n",
            "  %1123 : Float(*, *, *, device=cpu) = onnx::Sub(%1121, %1122)\n",
            "  %1124 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1125 : Float(*, *, *, device=cpu) = onnx::Pow(%1123, %1124)\n",
            "  %1126 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1125)\n",
            "  %1127 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1128 : Float(*, *, device=cpu) = onnx::Add(%1126, %1127)\n",
            "  %1129 : Float(*, *, device=cpu) = onnx::Sqrt(%1128)\n",
            "  %1130 : Float(*, *, *, device=cpu) = onnx::Div(%1123, %1129)\n",
            "  %1131 : Float(*, *, *, device=cpu) = onnx::Mul(%1130, %encoder.layer.7.attention.output.LayerNorm.weight)\n",
            "  %1132 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1131, %encoder.layer.7.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %1134 : Float(*, *, 3072, device=cpu) = onnx::MatMul(%1132, %1723)\n",
            "  %1135 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.7.intermediate.dense.bias, %1134) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1136 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %1137 : Float(*, *, 3072, device=cpu) = onnx::Div(%1135, %1136)\n",
            "  %1138 : Float(*, *, 3072, device=cpu) = onnx::Erf(%1137)\n",
            "  %1139 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1140 : Float(*, *, 3072, device=cpu) = onnx::Add(%1138, %1139)\n",
            "  %1141 : Float(*, *, 3072, device=cpu) = onnx::Mul(%1135, %1140)\n",
            "  %1142 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %1143 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Mul(%1141, %1142) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1556:0\n",
            "  %1145 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1143, %1724)\n",
            "  %1146 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.7.output.dense.bias, %1145) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %1147 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1146, %1132) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:425:0\n",
            "  %1148 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1147)\n",
            "  %1149 : Float(*, *, *, device=cpu) = onnx::Sub(%1147, %1148)\n",
            "  %1150 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1151 : Float(*, *, *, device=cpu) = onnx::Pow(%1149, %1150)\n",
            "  %1152 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1151)\n",
            "  %1153 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1154 : Float(*, *, device=cpu) = onnx::Add(%1152, %1153)\n",
            "  %1155 : Float(*, *, device=cpu) = onnx::Sqrt(%1154)\n",
            "  %1156 : Float(*, *, *, device=cpu) = onnx::Div(%1149, %1155)\n",
            "  %1157 : Float(*, *, *, device=cpu) = onnx::Mul(%1156, %encoder.layer.7.output.LayerNorm.weight)\n",
            "  %1158 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1157, %encoder.layer.7.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %1160 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1158, %1725)\n",
            "  %1161 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.8.attention.self.query.bias, %1160) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1163 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1158, %1726)\n",
            "  %1164 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.8.attention.self.key.bias, %1163) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1165 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1164)\n",
            "  %1166 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1167 : Long(device=cpu) = onnx::Gather[axis=0](%1165, %1166) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1168 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1164)\n",
            "  %1169 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1170 : Long(device=cpu) = onnx::Gather[axis=0](%1168, %1169) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1173 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1167)\n",
            "  %1174 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1170)\n",
            "  %1177 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1173, %1174, %1727, %1728)\n",
            "  %1178 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1164, %1177) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %1180 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1158, %1729)\n",
            "  %1181 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.8.attention.self.value.bias, %1180) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1182 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1181)\n",
            "  %1183 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1184 : Long(device=cpu) = onnx::Gather[axis=0](%1182, %1183) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1185 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1181)\n",
            "  %1186 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1187 : Long(device=cpu) = onnx::Gather[axis=0](%1185, %1186) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1190 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1184)\n",
            "  %1191 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1187)\n",
            "  %1194 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1190, %1191, %1730, %1731)\n",
            "  %1195 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1181, %1194) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %1196 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1195) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %1197 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1161)\n",
            "  %1198 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1199 : Long(device=cpu) = onnx::Gather[axis=0](%1197, %1198) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1200 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1161)\n",
            "  %1201 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1202 : Long(device=cpu) = onnx::Gather[axis=0](%1200, %1201) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1205 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1199)\n",
            "  %1206 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1202)\n",
            "  %1209 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1205, %1206, %1732, %1733)\n",
            "  %1210 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1161, %1209) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %1211 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1210) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %1212 : Float(*, *, *, *, strides=[49152, 64, 1, 768], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%1178) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %1213 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%1211, %1212) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %1214 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
            "  %1215 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Div(%1213, %1214)\n",
            "  %1216 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add(%1215, %218) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:311:0\n",
            "  %1217 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=3](%1216) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %1218 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%1217, %1196) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:324:0\n",
            "  %1219 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1218) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:326:0\n",
            "  %1220 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1219)\n",
            "  %1221 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1222 : Long(device=cpu) = onnx::Gather[axis=0](%1220, %1221) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %1223 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1219)\n",
            "  %1224 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1225 : Long(device=cpu) = onnx::Gather[axis=0](%1223, %1224) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %1227 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1222)\n",
            "  %1228 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1225)\n",
            "  %1230 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1227, %1228, %1734)\n",
            "  %1231 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1219, %1230) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:328:0\n",
            "  %1233 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1231, %1735)\n",
            "  %1234 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.8.attention.output.dense.bias, %1233) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %1235 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1234, %1158) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:347:0\n",
            "  %1236 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1235)\n",
            "  %1237 : Float(*, *, *, device=cpu) = onnx::Sub(%1235, %1236)\n",
            "  %1238 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1239 : Float(*, *, *, device=cpu) = onnx::Pow(%1237, %1238)\n",
            "  %1240 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1239)\n",
            "  %1241 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1242 : Float(*, *, device=cpu) = onnx::Add(%1240, %1241)\n",
            "  %1243 : Float(*, *, device=cpu) = onnx::Sqrt(%1242)\n",
            "  %1244 : Float(*, *, *, device=cpu) = onnx::Div(%1237, %1243)\n",
            "  %1245 : Float(*, *, *, device=cpu) = onnx::Mul(%1244, %encoder.layer.8.attention.output.LayerNorm.weight)\n",
            "  %1246 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1245, %encoder.layer.8.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %1248 : Float(*, *, 3072, device=cpu) = onnx::MatMul(%1246, %1736)\n",
            "  %1249 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.8.intermediate.dense.bias, %1248) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1250 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %1251 : Float(*, *, 3072, device=cpu) = onnx::Div(%1249, %1250)\n",
            "  %1252 : Float(*, *, 3072, device=cpu) = onnx::Erf(%1251)\n",
            "  %1253 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1254 : Float(*, *, 3072, device=cpu) = onnx::Add(%1252, %1253)\n",
            "  %1255 : Float(*, *, 3072, device=cpu) = onnx::Mul(%1249, %1254)\n",
            "  %1256 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %1257 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Mul(%1255, %1256) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1556:0\n",
            "  %1259 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1257, %1737)\n",
            "  %1260 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.8.output.dense.bias, %1259) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %1261 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1260, %1246) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:425:0\n",
            "  %1262 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1261)\n",
            "  %1263 : Float(*, *, *, device=cpu) = onnx::Sub(%1261, %1262)\n",
            "  %1264 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1265 : Float(*, *, *, device=cpu) = onnx::Pow(%1263, %1264)\n",
            "  %1266 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1265)\n",
            "  %1267 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1268 : Float(*, *, device=cpu) = onnx::Add(%1266, %1267)\n",
            "  %1269 : Float(*, *, device=cpu) = onnx::Sqrt(%1268)\n",
            "  %1270 : Float(*, *, *, device=cpu) = onnx::Div(%1263, %1269)\n",
            "  %1271 : Float(*, *, *, device=cpu) = onnx::Mul(%1270, %encoder.layer.8.output.LayerNorm.weight)\n",
            "  %1272 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1271, %encoder.layer.8.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %1274 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1272, %1738)\n",
            "  %1275 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.9.attention.self.query.bias, %1274) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1277 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1272, %1739)\n",
            "  %1278 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.9.attention.self.key.bias, %1277) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1279 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1278)\n",
            "  %1280 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1281 : Long(device=cpu) = onnx::Gather[axis=0](%1279, %1280) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1282 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1278)\n",
            "  %1283 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1284 : Long(device=cpu) = onnx::Gather[axis=0](%1282, %1283) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1287 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1281)\n",
            "  %1288 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1284)\n",
            "  %1291 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1287, %1288, %1740, %1741)\n",
            "  %1292 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1278, %1291) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %1294 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1272, %1742)\n",
            "  %1295 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.9.attention.self.value.bias, %1294) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1296 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1295)\n",
            "  %1297 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1298 : Long(device=cpu) = onnx::Gather[axis=0](%1296, %1297) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1299 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1295)\n",
            "  %1300 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1301 : Long(device=cpu) = onnx::Gather[axis=0](%1299, %1300) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1304 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1298)\n",
            "  %1305 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1301)\n",
            "  %1308 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1304, %1305, %1743, %1744)\n",
            "  %1309 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1295, %1308) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %1310 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1309) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %1311 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1275)\n",
            "  %1312 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1313 : Long(device=cpu) = onnx::Gather[axis=0](%1311, %1312) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1314 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1275)\n",
            "  %1315 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1316 : Long(device=cpu) = onnx::Gather[axis=0](%1314, %1315) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1319 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1313)\n",
            "  %1320 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1316)\n",
            "  %1323 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1319, %1320, %1745, %1746)\n",
            "  %1324 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1275, %1323) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %1325 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1324) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %1326 : Float(*, *, *, *, strides=[49152, 64, 1, 768], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%1292) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %1327 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%1325, %1326) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %1328 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
            "  %1329 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Div(%1327, %1328)\n",
            "  %1330 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add(%1329, %218) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:311:0\n",
            "  %1331 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=3](%1330) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %1332 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%1331, %1310) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:324:0\n",
            "  %1333 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1332) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:326:0\n",
            "  %1334 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1333)\n",
            "  %1335 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1336 : Long(device=cpu) = onnx::Gather[axis=0](%1334, %1335) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %1337 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1333)\n",
            "  %1338 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1339 : Long(device=cpu) = onnx::Gather[axis=0](%1337, %1338) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %1341 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1336)\n",
            "  %1342 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1339)\n",
            "  %1344 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1341, %1342, %1747)\n",
            "  %1345 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1333, %1344) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:328:0\n",
            "  %1347 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1345, %1748)\n",
            "  %1348 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.9.attention.output.dense.bias, %1347) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %1349 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1348, %1272) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:347:0\n",
            "  %1350 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1349)\n",
            "  %1351 : Float(*, *, *, device=cpu) = onnx::Sub(%1349, %1350)\n",
            "  %1352 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1353 : Float(*, *, *, device=cpu) = onnx::Pow(%1351, %1352)\n",
            "  %1354 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1353)\n",
            "  %1355 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1356 : Float(*, *, device=cpu) = onnx::Add(%1354, %1355)\n",
            "  %1357 : Float(*, *, device=cpu) = onnx::Sqrt(%1356)\n",
            "  %1358 : Float(*, *, *, device=cpu) = onnx::Div(%1351, %1357)\n",
            "  %1359 : Float(*, *, *, device=cpu) = onnx::Mul(%1358, %encoder.layer.9.attention.output.LayerNorm.weight)\n",
            "  %1360 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1359, %encoder.layer.9.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %1362 : Float(*, *, 3072, device=cpu) = onnx::MatMul(%1360, %1749)\n",
            "  %1363 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.9.intermediate.dense.bias, %1362) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1364 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %1365 : Float(*, *, 3072, device=cpu) = onnx::Div(%1363, %1364)\n",
            "  %1366 : Float(*, *, 3072, device=cpu) = onnx::Erf(%1365)\n",
            "  %1367 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1368 : Float(*, *, 3072, device=cpu) = onnx::Add(%1366, %1367)\n",
            "  %1369 : Float(*, *, 3072, device=cpu) = onnx::Mul(%1363, %1368)\n",
            "  %1370 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %1371 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Mul(%1369, %1370) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1556:0\n",
            "  %1373 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1371, %1750)\n",
            "  %1374 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.9.output.dense.bias, %1373) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %1375 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1374, %1360) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:425:0\n",
            "  %1376 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1375)\n",
            "  %1377 : Float(*, *, *, device=cpu) = onnx::Sub(%1375, %1376)\n",
            "  %1378 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1379 : Float(*, *, *, device=cpu) = onnx::Pow(%1377, %1378)\n",
            "  %1380 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1379)\n",
            "  %1381 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1382 : Float(*, *, device=cpu) = onnx::Add(%1380, %1381)\n",
            "  %1383 : Float(*, *, device=cpu) = onnx::Sqrt(%1382)\n",
            "  %1384 : Float(*, *, *, device=cpu) = onnx::Div(%1377, %1383)\n",
            "  %1385 : Float(*, *, *, device=cpu) = onnx::Mul(%1384, %encoder.layer.9.output.LayerNorm.weight)\n",
            "  %1386 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1385, %encoder.layer.9.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %1388 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1386, %1751)\n",
            "  %1389 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.10.attention.self.query.bias, %1388) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1391 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1386, %1752)\n",
            "  %1392 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.10.attention.self.key.bias, %1391) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1393 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1392)\n",
            "  %1394 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1395 : Long(device=cpu) = onnx::Gather[axis=0](%1393, %1394) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1396 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1392)\n",
            "  %1397 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1398 : Long(device=cpu) = onnx::Gather[axis=0](%1396, %1397) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1401 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1395)\n",
            "  %1402 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1398)\n",
            "  %1405 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1401, %1402, %1753, %1754)\n",
            "  %1406 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1392, %1405) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %1408 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1386, %1755)\n",
            "  %1409 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.10.attention.self.value.bias, %1408) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1410 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1409)\n",
            "  %1411 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1412 : Long(device=cpu) = onnx::Gather[axis=0](%1410, %1411) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1413 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1409)\n",
            "  %1414 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1415 : Long(device=cpu) = onnx::Gather[axis=0](%1413, %1414) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1418 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1412)\n",
            "  %1419 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1415)\n",
            "  %1422 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1418, %1419, %1756, %1757)\n",
            "  %1423 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1409, %1422) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %1424 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1423) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %1425 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1389)\n",
            "  %1426 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1427 : Long(device=cpu) = onnx::Gather[axis=0](%1425, %1426) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1428 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1389)\n",
            "  %1429 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1430 : Long(device=cpu) = onnx::Gather[axis=0](%1428, %1429) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1433 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1427)\n",
            "  %1434 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1430)\n",
            "  %1437 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1433, %1434, %1758, %1759)\n",
            "  %1438 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1389, %1437) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %1439 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1438) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %1440 : Float(*, *, *, *, strides=[49152, 64, 1, 768], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%1406) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %1441 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%1439, %1440) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %1442 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
            "  %1443 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Div(%1441, %1442)\n",
            "  %1444 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add(%1443, %218) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:311:0\n",
            "  %1445 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=3](%1444) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %1446 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%1445, %1424) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:324:0\n",
            "  %1447 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1446) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:326:0\n",
            "  %1448 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1447)\n",
            "  %1449 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1450 : Long(device=cpu) = onnx::Gather[axis=0](%1448, %1449) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %1451 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1447)\n",
            "  %1452 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1453 : Long(device=cpu) = onnx::Gather[axis=0](%1451, %1452) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %1455 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1450)\n",
            "  %1456 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1453)\n",
            "  %1458 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1455, %1456, %1760)\n",
            "  %1459 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1447, %1458) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:328:0\n",
            "  %1461 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1459, %1761)\n",
            "  %1462 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.10.attention.output.dense.bias, %1461) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %1463 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1462, %1386) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:347:0\n",
            "  %1464 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1463)\n",
            "  %1465 : Float(*, *, *, device=cpu) = onnx::Sub(%1463, %1464)\n",
            "  %1466 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1467 : Float(*, *, *, device=cpu) = onnx::Pow(%1465, %1466)\n",
            "  %1468 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1467)\n",
            "  %1469 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1470 : Float(*, *, device=cpu) = onnx::Add(%1468, %1469)\n",
            "  %1471 : Float(*, *, device=cpu) = onnx::Sqrt(%1470)\n",
            "  %1472 : Float(*, *, *, device=cpu) = onnx::Div(%1465, %1471)\n",
            "  %1473 : Float(*, *, *, device=cpu) = onnx::Mul(%1472, %encoder.layer.10.attention.output.LayerNorm.weight)\n",
            "  %1474 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1473, %encoder.layer.10.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %1476 : Float(*, *, 3072, device=cpu) = onnx::MatMul(%1474, %1762)\n",
            "  %1477 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.10.intermediate.dense.bias, %1476) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1478 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %1479 : Float(*, *, 3072, device=cpu) = onnx::Div(%1477, %1478)\n",
            "  %1480 : Float(*, *, 3072, device=cpu) = onnx::Erf(%1479)\n",
            "  %1481 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1482 : Float(*, *, 3072, device=cpu) = onnx::Add(%1480, %1481)\n",
            "  %1483 : Float(*, *, 3072, device=cpu) = onnx::Mul(%1477, %1482)\n",
            "  %1484 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %1485 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Mul(%1483, %1484) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1556:0\n",
            "  %1487 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1485, %1763)\n",
            "  %1488 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.10.output.dense.bias, %1487) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %1489 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1488, %1474) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:425:0\n",
            "  %1490 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1489)\n",
            "  %1491 : Float(*, *, *, device=cpu) = onnx::Sub(%1489, %1490)\n",
            "  %1492 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1493 : Float(*, *, *, device=cpu) = onnx::Pow(%1491, %1492)\n",
            "  %1494 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1493)\n",
            "  %1495 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1496 : Float(*, *, device=cpu) = onnx::Add(%1494, %1495)\n",
            "  %1497 : Float(*, *, device=cpu) = onnx::Sqrt(%1496)\n",
            "  %1498 : Float(*, *, *, device=cpu) = onnx::Div(%1491, %1497)\n",
            "  %1499 : Float(*, *, *, device=cpu) = onnx::Mul(%1498, %encoder.layer.10.output.LayerNorm.weight)\n",
            "  %1500 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1499, %encoder.layer.10.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %1502 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1500, %1764)\n",
            "  %1503 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.11.attention.self.query.bias, %1502) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1505 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1500, %1765)\n",
            "  %1506 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.11.attention.self.key.bias, %1505) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1507 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1506)\n",
            "  %1508 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1509 : Long(device=cpu) = onnx::Gather[axis=0](%1507, %1508) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1510 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1506)\n",
            "  %1511 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1512 : Long(device=cpu) = onnx::Gather[axis=0](%1510, %1511) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1515 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1509)\n",
            "  %1516 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1512)\n",
            "  %1519 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1515, %1516, %1766, %1767)\n",
            "  %1520 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1506, %1519) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %1522 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1500, %1768)\n",
            "  %1523 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.11.attention.self.value.bias, %1522) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1524 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1523)\n",
            "  %1525 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1526 : Long(device=cpu) = onnx::Gather[axis=0](%1524, %1525) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1527 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1523)\n",
            "  %1528 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1529 : Long(device=cpu) = onnx::Gather[axis=0](%1527, %1528) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1532 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1526)\n",
            "  %1533 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1529)\n",
            "  %1536 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1532, %1533, %1769, %1770)\n",
            "  %1537 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1523, %1536) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %1538 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1537) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %1539 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1503)\n",
            "  %1540 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1541 : Long(device=cpu) = onnx::Gather[axis=0](%1539, %1540) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1542 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1503)\n",
            "  %1543 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1544 : Long(device=cpu) = onnx::Gather[axis=0](%1542, %1543) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:238:0\n",
            "  %1547 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1541)\n",
            "  %1548 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1544)\n",
            "  %1551 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1547, %1548, %1771, %1772)\n",
            "  %1552 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1503, %1551) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:239:0\n",
            "  %1553 : Float(*, *, *, *, strides=[49152, 64, 768, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1552) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:240:0\n",
            "  %1554 : Float(*, *, *, *, strides=[49152, 64, 1, 768], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%1520) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %1555 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%1553, %1554) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:290:0\n",
            "  %1556 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
            "  %1557 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Div(%1555, %1556)\n",
            "  %1558 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add(%1557, %218) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:311:0\n",
            "  %1559 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=3](%1558) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %1560 : Float(*, *, *, *, strides=[49152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MatMul(%1559, %1538) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:324:0\n",
            "  %1561 : Float(*, *, *, *, strides=[49152, 768, 64, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1560) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:326:0\n",
            "  %1562 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1561)\n",
            "  %1563 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1564 : Long(device=cpu) = onnx::Gather[axis=0](%1562, %1563) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %1565 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1561)\n",
            "  %1566 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1567 : Long(device=cpu) = onnx::Gather[axis=0](%1565, %1566) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:327:0\n",
            "  %1569 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1564)\n",
            "  %1570 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1567)\n",
            "  %1572 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1569, %1570, %1773)\n",
            "  %1573 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Reshape(%1561, %1572) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:328:0\n",
            "  %1575 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1573, %1774)\n",
            "  %1576 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.11.attention.output.dense.bias, %1575) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %1577 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1576, %1500) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:347:0\n",
            "  %1578 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1577)\n",
            "  %1579 : Float(*, *, *, device=cpu) = onnx::Sub(%1577, %1578)\n",
            "  %1580 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1581 : Float(*, *, *, device=cpu) = onnx::Pow(%1579, %1580)\n",
            "  %1582 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1581)\n",
            "  %1583 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1584 : Float(*, *, device=cpu) = onnx::Add(%1582, %1583)\n",
            "  %1585 : Float(*, *, device=cpu) = onnx::Sqrt(%1584)\n",
            "  %1586 : Float(*, *, *, device=cpu) = onnx::Div(%1579, %1585)\n",
            "  %1587 : Float(*, *, *, device=cpu) = onnx::Mul(%1586, %encoder.layer.11.attention.output.LayerNorm.weight)\n",
            "  %1588 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1587, %encoder.layer.11.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2347:0\n",
            "  %1590 : Float(*, *, 3072, device=cpu) = onnx::MatMul(%1588, %1775)\n",
            "  %1591 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.11.intermediate.dense.bias, %1590) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1592 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %1593 : Float(*, *, 3072, device=cpu) = onnx::Div(%1591, %1592)\n",
            "  %1594 : Float(*, *, 3072, device=cpu) = onnx::Erf(%1593)\n",
            "  %1595 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1596 : Float(*, *, 3072, device=cpu) = onnx::Add(%1594, %1595)\n",
            "  %1597 : Float(*, *, 3072, device=cpu) = onnx::Mul(%1591, %1596)\n",
            "  %1598 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %1599 : Float(*, *, 3072, strides=[196608, 3072, 1], requires_grad=0, device=cpu) = onnx::Mul(%1597, %1598) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1556:0\n",
            "  %1601 : Float(*, *, 768, device=cpu) = onnx::MatMul(%1599, %1776)\n",
            "  %1602 : Float(*, *, 768, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%encoder.layer.11.output.dense.bias, %1601) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1169:0\n",
            "  %1603 : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1602, %1588) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:425:0\n",
            "  %1604 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1603)\n",
            "  %1605 : Float(*, *, *, device=cpu) = onnx::Sub(%1603, %1604)\n",
            "  %1606 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1607 : Float(*, *, *, device=cpu) = onnx::Pow(%1605, %1606)\n",
            "  %1608 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1607)\n",
            "  %1609 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1610 : Float(*, *, device=cpu) = onnx::Add(%1608, %1609)\n",
            "  %1611 : Float(*, *, device=cpu) = onnx::Sqrt(%1610)\n",
            "  %1612 : Float(*, *, *, device=cpu) = onnx::Div(%1605, %1611)\n",
            "  %1613 : Float(*, *, *, device=cpu) = onnx::Mul(%1612, %encoder.layer.11.output.LayerNorm.weight)\n",
            "  %output : Float(*, *, *, strides=[49152, 768, 1], requires_grad=0, device=cpu) = onnx::Add(%1613, %encoder.layer.11.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:618:0\n",
            "  %1615 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1616 : Float(*, *, strides=[49152, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%output, %1615) # /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py:618:0\n",
            "  %1617 : Float(*, 768, strides=[768, 1], requires_grad=0, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%1616, %pooler.dense.weight, %pooler.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1848:0\n",
            "  %1618 : Float(*, 768, strides=[768, 1], requires_grad=0, device=cpu) = onnx::Tanh(%1617) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py:349:0\n",
            "  return (%output, %1618)\n",
            "\n",
            "ONNX Model exported to bert.onnx\n"
          ]
        }
      ],
      "source": [
        "def export_onnx_model(model, onnx_model_path):\n",
        "    with torch.no_grad():\n",
        "        inputs = {'input_ids':      torch.ones(1, 64, dtype=torch.int64),\n",
        "            'attention_mask': torch.ones(1, 64, dtype=torch.int64)}\n",
        "        outputs = model(encoded_dict[\"input_ids\"], encoded_dict[\"attention_mask\"])\n",
        "        symbolic_names = {0: 'batch_size', 1: 'max_seq_len'}\n",
        "        torch.onnx.export(model,                                            # model being run\n",
        "                    (inputs['input_ids'],                             # model input (or a tuple for multiple inputs)\n",
        "                    inputs['attention_mask']),                                       # model input (or a tuple for multiple inputs)\n",
        "                    onnx_model_path,                                # where to save the model (can be a file or file-like object)\n",
        "                    opset_version=11,\n",
        "                    verbose=True,                                 # the ONNX version to export the model to\n",
        "                    do_constant_folding=True,                         # whether to execute constant folding for optimization\n",
        "                    input_names=['input_ids',                         # the model's input names\n",
        "                                'attention_mask'],\n",
        "                    output_names=['output'],                    # the model's output names\n",
        "                    dynamic_axes={'input_ids': symbolic_names,        # variable length axes\n",
        "                                'attention_mask' : symbolic_names})\n",
        "        print(\"ONNX Model exported to {0}\".format(onnx_model_path))\n",
        "\n",
        "export_onnx_model(transformer, \"bert.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QnzbDK-4tfR",
        "outputId": "0b74d1f1-c8ff-4841-c68f-536866ed2b7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX full precision model size (MB): 414.75461196899414\n",
            "ONNX quantized model size (MB): 104.79691123962402\n"
          ]
        }
      ],
      "source": [
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "import os\n",
        "quantized_onnx_model_path = 'quantizebert1.onnx'\n",
        "quantize_dynamic(\n",
        "    '/content/bert.onnx',\n",
        "    quantized_onnx_model_path,\n",
        "    activation_type=QuantType.QUInt8,\n",
        "    weight_type=QuantType.QUInt8\n",
        ")\n",
        "print('ONNX full precision model size (MB):', os.path.getsize('/content/bert.onnx') / (1024 * 1024))\n",
        "print('ONNX quantized model size (MB):', os.path.getsize(quantized_onnx_model_path) / (1024 * 1024))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GANBERT_pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "db3276f74dec405c98d9af0131dfb8d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e9eb71d99c6643ebad3c58cbec114e87",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1c1b7b310796418f9e218a9ad05f9eb6",
              "IPY_MODEL_309f1423c3b8496681b5c9a7a7a1adf1",
              "IPY_MODEL_2ba14342d4b64dad9e2308e02cb02d4c"
            ]
          }
        },
        "e9eb71d99c6643ebad3c58cbec114e87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c1b7b310796418f9e218a9ad05f9eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a4ab832eb9fa45aa8ddf7a477cd29ec9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af87a25ae48849eab0a17c7262529512"
          }
        },
        "309f1423c3b8496681b5c9a7a7a1adf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6ad9a04a5c8a4c65bf8d9d1b45cf8055",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0766a1edec3d435ca50a4996f49ca495"
          }
        },
        "2ba14342d4b64dad9e2308e02cb02d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_146ef28931ce457187c8160f2e07f260",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 6.51kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f773ce16b5d44bd1b8ae6e1b85734424"
          }
        },
        "a4ab832eb9fa45aa8ddf7a477cd29ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af87a25ae48849eab0a17c7262529512": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ad9a04a5c8a4c65bf8d9d1b45cf8055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0766a1edec3d435ca50a4996f49ca495": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "146ef28931ce457187c8160f2e07f260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f773ce16b5d44bd1b8ae6e1b85734424": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8570e7609ee428dbde87e174695df9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e5ae13832aa942d1987d3ed5940d2a62",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d34538c4da484f4b84e6e50755a68a30",
              "IPY_MODEL_67b6da7e955a41e1bb48ecfead248ae8",
              "IPY_MODEL_c5f7afa4dcc84134adc06bb4f5710c9f"
            ]
          }
        },
        "e5ae13832aa942d1987d3ed5940d2a62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d34538c4da484f4b84e6e50755a68a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0d6c1c61001642f4a174b3fa16935b1f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3291352c01fb402ab0795dbe3deb5851"
          }
        },
        "67b6da7e955a41e1bb48ecfead248ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0c2df3b9257e4a20ba752a1f3eaaf659",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44e42607e9d94eb7a81b2bb756ed1142"
          }
        },
        "c5f7afa4dcc84134adc06bb4f5710c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1d85ff9d1051480ca6c6e42de0c27fc7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:32&lt;00:00, 15.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d8dd7bb2ca4d40da90eb1ded8f091c30"
          }
        },
        "0d6c1c61001642f4a174b3fa16935b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3291352c01fb402ab0795dbe3deb5851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c2df3b9257e4a20ba752a1f3eaaf659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "44e42607e9d94eb7a81b2bb756ed1142": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d85ff9d1051480ca6c6e42de0c27fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d8dd7bb2ca4d40da90eb1ded8f091c30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2da70e3699a414688b6d30ea26b883c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_47c4899b04af41b0846740a3cf7f194a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b743c5c960434339801a1ecc8eac4a08",
              "IPY_MODEL_7b7f4915558948e08adbc6d46b5fb012",
              "IPY_MODEL_b1d60409ac5c4687aadee294b3d1d3cb"
            ]
          }
        },
        "47c4899b04af41b0846740a3cf7f194a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b743c5c960434339801a1ecc8eac4a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_608b69a23c254f00adf53e72bffb5b93",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca0e0008c3594639a5b84df909f0e477"
          }
        },
        "7b7f4915558948e08adbc6d46b5fb012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_316c589efcbe40708a355780612328d1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cdcfe783b4e445e0a73bc3da5cbeffb0"
          }
        },
        "b1d60409ac5c4687aadee294b3d1d3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dcc413ecd5304b5aa0ad24b35e7b4eb3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 294kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c39bc37224449cab625edd332fc999e"
          }
        },
        "608b69a23c254f00adf53e72bffb5b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca0e0008c3594639a5b84df909f0e477": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "316c589efcbe40708a355780612328d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cdcfe783b4e445e0a73bc3da5cbeffb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dcc413ecd5304b5aa0ad24b35e7b4eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c39bc37224449cab625edd332fc999e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92d754c40ad049e18bd6b18e352b52f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7e176837f33b450e90b6d7c3ff72c498",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a71c6fb4b1f3412488a378d667270454",
              "IPY_MODEL_9063a317e9524b189e28edc40ec49b9c",
              "IPY_MODEL_b48443b07cc14955bbfd8bb6a0dc5acb"
            ]
          }
        },
        "7e176837f33b450e90b6d7c3ff72c498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a71c6fb4b1f3412488a378d667270454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_42346f3ad2684476a33ff8204e5782e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e1d8d7f01bcf4fd5917a6e8138a2dbce"
          }
        },
        "9063a317e9524b189e28edc40ec49b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f2f6a20fbd8d4772874c6dc0b023df02",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a17014fdee44fc484e198cd3e0590ab"
          }
        },
        "b48443b07cc14955bbfd8bb6a0dc5acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c456f636b2cb46adbc836bb544dbac24",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436k/436k [00:00&lt;00:00, 669kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_967cc8fa506443eba1c9a8870801da3d"
          }
        },
        "42346f3ad2684476a33ff8204e5782e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e1d8d7f01bcf4fd5917a6e8138a2dbce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2f6a20fbd8d4772874c6dc0b023df02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a17014fdee44fc484e198cd3e0590ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c456f636b2cb46adbc836bb544dbac24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "967cc8fa506443eba1c9a8870801da3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8cb10fc6bcea4b1bba6a297590d734f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_722bc21fb2014432bef6929b376e938d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_39128d6d796e40eea93edd2cb2db9f80",
              "IPY_MODEL_1b1a90ef109c4918838a4bf50fafa139",
              "IPY_MODEL_9c9bb34d048f4c08a649e526cccb9e9f"
            ]
          }
        },
        "722bc21fb2014432bef6929b376e938d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39128d6d796e40eea93edd2cb2db9f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7d6025575fd644a09b33fcf0fdd169ae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5ead7eeacd64b94862fb8ece7839d19"
          }
        },
        "1b1a90ef109c4918838a4bf50fafa139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c64becf8e2f45d2af1ee16e0df13f9a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c771720452ce47399fe09343670a672d"
          }
        },
        "9c9bb34d048f4c08a649e526cccb9e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_29a8851095b846439bb87e69bb7abea2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 8.98kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_107936edf3a94ba99caf0d5de9719af0"
          }
        },
        "7d6025575fd644a09b33fcf0fdd169ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5ead7eeacd64b94862fb8ece7839d19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c64becf8e2f45d2af1ee16e0df13f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c771720452ce47399fe09343670a672d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29a8851095b846439bb87e69bb7abea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "107936edf3a94ba99caf0d5de9719af0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2dc26f146b95493bb1510596f810ee3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_adbb88f8a62342989b397c78c7c84103",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_83cd924ab9954ebbbba49d1e3520c6d1",
              "IPY_MODEL_5a495f8cb2b3480d9ceaea787531ac5f",
              "IPY_MODEL_a42ade9216fe40c199ce075ba5ec0107"
            ]
          }
        },
        "adbb88f8a62342989b397c78c7c84103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83cd924ab9954ebbbba49d1e3520c6d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_659527d2fe9d485886c4ff3fba9f6e88",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e718efddb32245fc8fc2c87f69fd3d89"
          }
        },
        "5a495f8cb2b3480d9ceaea787531ac5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_36666c77ec1542abbb1bb4d9bc49fc1a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ebd4f61db33e4f4e994fc17b6ebeccca"
          }
        },
        "a42ade9216fe40c199ce075ba5ec0107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d026410f378d4840a22885cb0beef6d8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 323kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3123da93c8914842bf5bd2afb61e7c91"
          }
        },
        "659527d2fe9d485886c4ff3fba9f6e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e718efddb32245fc8fc2c87f69fd3d89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36666c77ec1542abbb1bb4d9bc49fc1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ebd4f61db33e4f4e994fc17b6ebeccca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d026410f378d4840a22885cb0beef6d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3123da93c8914842bf5bd2afb61e7c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3092fd4dc5f140f291cbd3d733786042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_136f7b25b2c54ae1b57127828ccfb9a7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f33b9f20dff49f3a7f9280d7a9038f9",
              "IPY_MODEL_390cc8d45a2c45929249a99fca3f4a1a",
              "IPY_MODEL_1f2a30bdde554528be9b698bdd4111b0"
            ]
          }
        },
        "136f7b25b2c54ae1b57127828ccfb9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f33b9f20dff49f3a7f9280d7a9038f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_70b287b926874843a28c840b6cb43536",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f4f3549ee9c047d186ac85ef29376740"
          }
        },
        "390cc8d45a2c45929249a99fca3f4a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a88a9d3b1364465b9073428a648b0bcd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c50d234edbbc458a889e6de861ac5c67"
          }
        },
        "1f2a30bdde554528be9b698bdd4111b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e8fa91e8c2e245ae9decd78274e1b823",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436k/436k [00:00&lt;00:00, 652kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87f1706a77114eae8cc08f63cbca830b"
          }
        },
        "70b287b926874843a28c840b6cb43536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f4f3549ee9c047d186ac85ef29376740": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a88a9d3b1364465b9073428a648b0bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c50d234edbbc458a889e6de861ac5c67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8fa91e8c2e245ae9decd78274e1b823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87f1706a77114eae8cc08f63cbca830b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}